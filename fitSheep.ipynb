{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from math import *\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "myFmt = mdates.DateFormatter('%Hh')\n",
    "\n",
    "import pandas as pd\n",
    "np.set_printoptions(suppress=True,precision=6)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "plt.style.use('ggplot') \n",
    "plt.style.use('seaborn-paper') \n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "import sys\n",
    "\n",
    "from tensorflow_probability import distributions as tfd\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from move_ns import moveNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and display individual time series lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up lower level GP locations covering 24 hours\n",
    "Z = np.linspace(0,24,num=25,endpoint=False).astype(np.float64)[:,None]\n",
    "#np.random.shuffle(Z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_data(skip_i=1,skip=3):\n",
    "    \n",
    "    df = pd.read_csv('data/ovejas.csv')\n",
    "\n",
    "    df = df[df.id!=34]\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    df['ID'] = df['id'].astype('category').cat.rename_categories(range(0, df['id'].nunique())).astype('int')\n",
    "    df = df[df['ID']%skip_i==0]\n",
    "    #df = df[df['ID'].isin(np.arange(0,20,2))]\n",
    "    \n",
    "    ID = df['ID'].values \n",
    "    \n",
    "    \n",
    "    \n",
    "    Xgps = df[['lat','lon']].values\n",
    "    minX = np.min(Xgps[:,0])\n",
    "    minY = np.min(Xgps[:,1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    secs =(pd.to_datetime(df['time'])- pd.datetime(2018,1,1)).dt.seconds.astype(float).values\n",
    "    days = (pd.to_datetime(df['time'])- pd.datetime(2018,1,1)).dt.days.astype(float).values\n",
    "    T = (days*24*60+secs/60)/(60*24) #days\n",
    "    T = T-np.min(T)\n",
    "\n",
    "    rescale = 24  # use hours to improve numerical stability\n",
    "    T = T * rescale\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # use geodesic to get the straight line distance between two points\n",
    "    Xmetres = np.array([geodesic((xloc,minY), (minX,minY)).meters for xloc in Xgps[:,0]])\n",
    "    Ymetres = np.array([geodesic((minX,yloc), (minX,minY)).meters for yloc in Xgps[:,1]])\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    X = np.array([Xmetres, Ymetres]).T\n",
    "    \n",
    "    T=T[::skip,None]\n",
    "    X=X[::skip]\n",
    "    ID=ID[::skip]\n",
    "\n",
    "    return X, T, ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0,20,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-3da508b15eb6>:26: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  secs =(pd.to_datetime(df['time'])- pd.datetime(2018,1,1)).dt.seconds.astype(float).values\n",
      "<ipython-input-3-3da508b15eb6>:27: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  days = (pd.to_datetime(df['time'])- pd.datetime(2018,1,1)).dt.days.astype(float).values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(225953, 2)\n"
     ]
    }
   ],
   "source": [
    "X,T,ID = setup_data(skip_i=1,skip=2)\n",
    "X[:,0] = X[:,0]-X[:,0].mean()\n",
    "X[:,1] = X[:,1]-X[:,1].mean()\n",
    "X[:,0] = X[:,0]/1000\n",
    "X[:,1] = X[:,1]/1000\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_shift(x):\n",
    "    # softplus transform with shift \n",
    "    return tf.nn.softplus(x)+1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up the non-stationary GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def periodic_kernel(x1,x2):\n",
    "    # periodic kernel with parameter set to encode\n",
    "    # daily activity pattern (period=rescale).\n",
    "    return tfp.math.psd_kernels.ExpSinSquared(x1,x2,np.float64(24.0))\n",
    "\n",
    "# transform for parameter to ensure positive\n",
    "transforms=[sp_shift,sp_shift] \n",
    "#transforms=[sp_shift] \n",
    "\n",
    "# diffuse priors on parameters\n",
    "lpriors = [tfd.Normal(loc = np.float64(0),scale=np.float64(1)),\n",
    "           tfd.Normal(loc = np.float64(0),scale=np.float64(10.))]\n",
    "           \n",
    "apriors = [tfd.Normal(loc = np.float64(0.),scale=np.float64(1)),\n",
    "           tfd.Normal(loc = np.float64(0),scale=np.float64(10.))]\n",
    "\n",
    "\n",
    "lparams_init = [0.0,0.0]\n",
    "aparams_init = [0.0,0.0]\n",
    "\n",
    "\n",
    "# create the model #2880\n",
    "mover = moveNS(T,X,Z, ID, BATCH_SIZE=1000, MIN_REMAIN=500,velocity=True, std_obs_noise=100, mean_obs_noise=10,\n",
    "                        akernel=periodic_kernel, \n",
    "                        aparams_init=aparams_init, \n",
    "                        apriors=apriors, \n",
    "                        atransforms=transforms,\n",
    "                        lkernel=periodic_kernel, \n",
    "                        lparams_init=lparams_init, \n",
    "                        lpriors=lpriors, \n",
    "                        ltransforms=transforms)\n",
    "\n",
    "\n",
    "#-mover.log_posterior(*mover.kernel_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss 152143.739039:  12%|█▏        | 233/2000 [09:58<1:15:13,  2.55s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "learning_rate = tf.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-1,\n",
    "    decay_steps=50,\n",
    "    decay_rate=0.99,\n",
    "    staircase=True)\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate,beta_2=0.99)\n",
    "train_steps = 2000\n",
    "pbar = tqdm(range(train_steps))\n",
    "loss_history = np.zeros((train_steps))\n",
    "for i in pbar:\n",
    "    with tf.GradientTape() as t:\n",
    "        loss = -mover.log_posterior(*mover.kernel_params)\n",
    "    loss_history[i] = loss.numpy()\n",
    "    pbar.set_description(\"Loss %f\" % (loss_history[i]))\n",
    "\n",
    "    gradients = t.gradient(loss, mover.kernel_params)\n",
    "    optimizer.apply_gradients(zip(gradients, mover.kernel_params))\n",
    "#n=3.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_history[800:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = mover.get_lengthscale()\n",
    "plt.plot(Z,lengths,'o',c='b')\n",
    "Zin = np.linspace(0,24,num=500,endpoint=False).astype(np.float64)[:,None]\n",
    "\n",
    "lengths = mover.get_lengthscale(X=Zin)\n",
    "plt.plot(Zin,lengths)\n",
    "plt.show()\n",
    "\n",
    "amps = mover.get_amplitude()\n",
    "plt.plot(Z,amps,'o',c='b')\n",
    "Zin = np.linspace(0,24,num=500,endpoint=False).astype(np.float64)[:,None]\n",
    "amps = mover.get_amplitude(X=Zin)\n",
    "plt.plot(Zin,amps)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params = [i.numpy() for i in  mover.kernel_params]\n",
    "\n",
    "with open('opt_params.npy', 'wb') as fp:\n",
    "    pickle.dump(opt_params, fp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('opt_params.npy', 'rb') as fp:\n",
    "    opt_params = pickle.load(fp)\n",
    "    opt_obs_noise = opt_params[0]\n",
    "    opt_ls_v = opt_params[1]\n",
    "    opt_ls_amp = sp_shift(opt_params[2]).numpy()\n",
    "    opt_ls_ls = sp_shift(opt_params[3]).numpy()\n",
    "    opt_amp_v = opt_params[4]\n",
    "    opt_amp_amp = sp_shift(opt_params[5]).numpy()\n",
    "    opt_amp_ls = sp_shift(opt_params[6]).numpy()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ls_periodic_kernel():\n",
    "    # periodic kernel with single variable parameter. Other parameters are set \n",
    "    # to encode daily activity pattern (period=rescale).\n",
    "    # 15 minute correlation time\n",
    "    return tfp.math.psd_kernels.ExpSinSquared(np.float64(opt_ls_amp),np.float64(opt_ls_ls),np.float64(24.0))\n",
    "\n",
    "def amp_periodic_kernel():\n",
    "    # periodic kernel with single variable parameter. Other parameters are set \n",
    "    # to encode daily activity pattern (period=rescale).\n",
    "    # 15 minute correlation time\n",
    "    return tfp.math.psd_kernels.ExpSinSquared(np.float64(opt_amp_amp),np.float64(opt_amp_ls),np.float64(24.0))\n",
    "\n",
    "\n",
    "# transform for parameter to ensure positive\n",
    "transforms=[] \n",
    "\n",
    "# prior distribution on parameters - changed to 20 \n",
    "lpriors =[]#tfd.Normal(loc = np.float64(opt_ls_mean),scale=np.float64(10))]\n",
    "apriors =[]#tfd.Normal(loc = np.float64(opt_amp_mean),scale=np.float64(10))]\n",
    "\n",
    "# random initial values of mean and kernel amplitude\n",
    "lparams_init =[]\n",
    "aparams_init = []\n",
    "\n",
    "# create the model \n",
    "\n",
    "\n",
    "mover_hmc = moveNS(T,X,Z, ID, BATCH_SIZE=1000, MIN_REMAIN= 500, velocity=True, std_obs_noise=0, mean_obs_noise=opt_obs_noise,\n",
    "                        akernel=amp_periodic_kernel, \n",
    "                        aparams_init=aparams_init, \n",
    "                        apriors=apriors, \n",
    "                        atransforms=transforms,\n",
    "                        lkernel=ls_periodic_kernel, \n",
    "                        lparams_init=lparams_init, \n",
    "                        lpriors=lpriors, \n",
    "                        ltransforms=transforms)\n",
    "\n",
    "mover_hmc.kernel_params[0].assign(opt_ls_v)\n",
    "mover_hmc.kernel_params[1].assign(opt_amp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mover_hmc.mala_sample(num_samples=500,skip=10,burn_in=20000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def log_normal_pdf_unn(x, mean, variance, inv_variance=None):\n",
    "    \"\"\"\n",
    "    log of unnormalized pdf of a normal distribution.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x\n",
    "        Where to evaluate the Normal.\n",
    "    mean, variance:\n",
    "        parameters of the gaussian.\n",
    "    inv_variance\n",
    "        Inverse of the variance (to avoid computing it again and again in certain cases).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float: the result.\n",
    "    \"\"\"\n",
    "    if inv_variance is None:\n",
    "        inv_variance = np.linalg.inv(variance)\n",
    "    return -1 / 2 * (x - mean) @ (inv_variance @ (x - mean))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def projection_operators(epsilon_1, A_1):\n",
    "    \"\"\"\n",
    "    Return the projection functions defined in the article.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    epsilon_1, A_1:\n",
    "        The two scaling operators.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    proj_sigma: Projection on segment epsilon_1, A_1\n",
    "    proj_gamma: Projection on cone of definite matrix of norm < 1_1\n",
    "    proj_mu: Projection on centered ball of radius A_1\n",
    "    \"\"\"\n",
    "\n",
    "    def proj_sigma(x: float) -> float:\n",
    "        if x < epsilon_1:\n",
    "            return epsilon_1\n",
    "        elif x > A_1:\n",
    "            return A_1\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def proj_gamma(x: np.ndarray) -> np.ndarray:\n",
    "        assert x.ndim == 2\n",
    "        norm = np.linalg.norm(x, ord='fro')  # Frobenius norm\n",
    "        if norm > A_1:\n",
    "            print(f\"Projection on Gamma! norm={norm:.1e}\")\n",
    "            return A_1 / norm * x\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def proj_mu(x: np.ndarray) -> np.ndarray:\n",
    "        assert x.ndim == 1\n",
    "        norm = np.linalg.norm(x, ord=2)\n",
    "        if norm > A_1:\n",
    "            print(f\"Projection on mu! norm={norm:.1e}\")\n",
    "            return A_1 / norm * x\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    return proj_sigma, proj_gamma, proj_mu\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "class AdaptiveMALA():\n",
    "    def __init__(self, state, log_pdf,\n",
    "                 drift,\n",
    "                 epsilon_1=1e-5,\n",
    "                 epsilon_2=1e-6,\n",
    "                 A_1=1e7,\n",
    "                 tau_bar=0.574,\n",
    "                 mu_0=None,\n",
    "                 gamma_0=None,\n",
    "                 sigma_0=1,\n",
    "                 robbins_monroe=10,\n",
    "                 threshold_start_estimate=100,\n",
    "                 threshold_use_estimate=200,\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        Adaptative MALA sampler, described in [1].\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        state: initial state to start in.\n",
    "        pi: Callable. Unnormalized pdf of the distribution we want to approximate.\n",
    "        log_pi: log of the distribution we want to approximate\n",
    "        drift: Callable.\n",
    "        epsilon_1, epsilon_2, A_1: parameters of the HM algorithm. Must verify: 0 < epsilon_1 < A_1, 0 < epsilon_2.\n",
    "        tau_bar: target optimal acceptation rate.\n",
    "        mu_0, gamma_0, sigma_0: initial values for the parameters.\n",
    "        robbins_monroe: constant c_0 for the robbins monroe coefficients: g_n = c_0/n\n",
    "        threshold_use_estimate: int corresponding to the number of steps after which we start updating the covariance\n",
    "        matrix\n",
    "\n",
    "        References\n",
    "        ----------\n",
    "        [1] An adaptive version for the Metropolis adjusted Langevin algorithm with a truncated drift, Yves F. Atchadé\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        self.dims = state.shape[0]\n",
    "        self.state = state\n",
    "        self.log_pdf = log_pdf\n",
    "        self.acceptance_rate = 0\n",
    "        self.steps = 0\n",
    "        self.history = {'state': [state], 'acceptance rate': []}\n",
    "\n",
    "        if mu_0 is None:\n",
    "            mu_0 = state\n",
    "        if gamma_0 is None:\n",
    "            gamma_0 = np.eye(self.dims)\n",
    "\n",
    "        self.drift = drift\n",
    "        self.tau_bar = tau_bar\n",
    "        self.gamma = gamma_0\n",
    "        self.sigma = sigma_0\n",
    "        self.A_1 = A_1\n",
    "        self.epsilon_1 = epsilon_1\n",
    "        self.epsilon_2 = epsilon_2\n",
    "        self.c_0 = robbins_monroe\n",
    "        self._gamma_estimate = self.gamma.copy()\n",
    "        self.params_history = {'gamma': [gamma_0.copy()],'sigma': [sigma_0]}\n",
    "\n",
    "\n",
    "        self.epsilon_1 = epsilon_1\n",
    "\n",
    "        self.mu = mu_0\n",
    "        self.proj_sigma, self.proj_gamma, self.proj_mu = projection_operators(epsilon_1, A_1)\n",
    "        self.threshold_use_estimate = threshold_use_estimate\n",
    "        self.threshold_start_estimate = threshold_start_estimate\n",
    "        self.params_history['mu'] = [mu_0.copy()]\n",
    "\n",
    "    \n",
    "    def run_sampler(self,n_samples, n_burn, thin=1):\n",
    "        \"\"\"\n",
    "        Draw samples from the chain.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        The new state.\n",
    "        \"\"\"\n",
    "        self.steps = 0\n",
    "        \n",
    "        samples = np.zeros((n_samples,self.dims))\n",
    "        \n",
    "        # total iterations for number of samples\n",
    "        iters = (n_samples * thin) + n_burn\n",
    "        \n",
    "        \n",
    "        pbar = tqdm(range(iters))\n",
    "        self.state_log_pdf = self.log_pdf(self.state)\n",
    "        self.state_drift = self.drift(self.state)\n",
    "        for i in pbar:\n",
    "            self.steps += 1\n",
    "            self.proposal = self.proposal_sampler()\n",
    "            self.proposal_log_pdf = self.log_pdf(self.proposal)\n",
    "            self.proposal_drift = self.drift(self.proposal)\n",
    "\n",
    "            alpha = self.acceptance_ratio()\n",
    "            \n",
    "            u = np.random.uniform(0, 1)\n",
    "            if u <= alpha:\n",
    "                self.state = self.proposal\n",
    "                self.acceptance_rate = ((self.steps - 1) * self.acceptance_rate + 1) / self.steps\n",
    "                self.state_log_pdf = self.proposal_log_pdf.copy()\n",
    "                self.state_drift = self.proposal_drift.copy()\n",
    "\n",
    "            else:\n",
    "                self.acceptance_rate = ((self.steps - 1) * self.acceptance_rate) / self.steps\n",
    "            pbar.set_description(\"AR %f SS %f\" % (self.acceptance_rate,self.sigma))\n",
    "\n",
    "            self.history['state'].append(self.state.copy())\n",
    "            self.history['acceptance rate'].append(self.acceptance_rate)\n",
    "\n",
    "            #print(self.state[0])\n",
    "            if i >= n_burn and i % thin == 0:\n",
    "                samples[(i - n_burn) // thin] = self.state\n",
    "\n",
    "            if i < n_burn:\n",
    "                self.update_params(alpha=alpha)\n",
    "            assert np.isfinite(self.state).all()\n",
    "            assert np.isfinite(self.gamma).all()\n",
    "\n",
    "        return samples\n",
    "    \n",
    "\n",
    "    \n",
    "    def acceptance_ratio(self):\n",
    "        \"\"\"\n",
    "        Compute the alpha parameter for the proposal, given the state we are in (self.state).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        proposal\n",
    "            The proposal value, given by e.g. proposal_sampler()\n",
    "        log\n",
    "            Computing acceptance_ratio using log trick\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A float between 0 and 1.\n",
    "        \"\"\"\n",
    "        \n",
    "        arg_exp = self.proposal_log_pdf - self.state_log_pdf \\\n",
    "                  + self.fwd_log_proposal_value() - self.bkwd_log_proposal_value()\n",
    "        #arg_exp = arg_exp.numpy()\n",
    "        if np.isfinite(arg_exp):\n",
    "            alpha = np.exp(min(0, arg_exp))\n",
    "        else:\n",
    "            alpha=0\n",
    "        \n",
    "        return alpha\n",
    "    \n",
    "    def proposal_sampler(self) -> np.ndarray:\n",
    "        big_lambda = self.gamma + self.epsilon_2 * np.eye(self.dims)\n",
    "        mean = self.state + self.sigma ** 2 / 2 * big_lambda @ self.state_drift\n",
    "        variance = self.sigma ** 2 * big_lambda\n",
    "        sample = np.random.multivariate_normal(mean=mean, cov=variance)\n",
    "        return sample\n",
    "\n",
    "    def fwd_log_proposal_value(self):\n",
    "        big_lambda = self.gamma + self.epsilon_2 * np.eye(self.dims)\n",
    "        mean = self.proposal + self.sigma ** 2 / 2 * big_lambda @ self.proposal_drift\n",
    "        variance = self.sigma ** 2 * big_lambda\n",
    "        value = log_normal_pdf_unn(self.state, mean, variance)\n",
    "        return value\n",
    "\n",
    "    def bkwd_log_proposal_value(self):\n",
    "        big_lambda = self.gamma + self.epsilon_2 * np.eye(self.dims)\n",
    "        mean = self.state + self.sigma ** 2 / 2 * big_lambda @ self.state_drift\n",
    "        variance = self.sigma ** 2 * big_lambda\n",
    "        value = log_normal_pdf_unn(self.proposal, mean, variance)\n",
    "        return value\n",
    "    \n",
    "    def log_proposal_value(self, x, y):\n",
    "        big_lambda = self.gamma + self.epsilon_2 * np.eye(self.dims)\n",
    "        mean = x + self.sigma ** 2 / 2 * big_lambda @ self.drift(x)\n",
    "        variance = self.sigma ** 2 * big_lambda\n",
    "        value = log_normal_pdf_unn(y, mean, variance)\n",
    "        return value\n",
    "\n",
    "\n",
    "    def update_params(self, alpha):\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model: instance of AdaptiveMALA or AdaptiveSymmetricRW\n",
    "        alpha: the acceptance ratio\n",
    "\n",
    "        Updates the parameters of the instance.\n",
    "        \"\"\"\n",
    "        coeff = self.c_0 / self.steps\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        # _gamma_estimate holds the estimation of the covariance matrix.\n",
    "        # It is different from gamma: indeed, we want to estimate the covariance matrix without using it at first.\n",
    "        if self.steps > self.threshold_start_estimate:\n",
    "            coeff_gamma = self.c_0 / (self.steps - self.threshold_start_estimate)\n",
    "            covariance = (self.state - self.mu)[:, np.newaxis] @ (self.state - self.mu)[np.newaxis, :]\n",
    "            #covariance = np.diag((self.state - self.mu)**2)\n",
    "\n",
    "            self._gamma_estimate = self.proj_gamma(self._gamma_estimate + coeff_gamma * (covariance - self._gamma_estimate))\n",
    "        if self.steps > self.threshold_use_estimate:\n",
    "            self.gamma = self._gamma_estimate\n",
    "        \n",
    "        \n",
    "        self.mu = self.proj_mu(self.mu + coeff * (self.state - self.mu))\n",
    "\n",
    "        self.params_history['gamma'].append(self.gamma.copy())\n",
    "        self.params_history['mu'].append(self.mu.copy())\n",
    "\n",
    "        \n",
    "        self.sigma = self.proj_sigma(self.sigma + coeff * (alpha - self.tau_bar))\n",
    "        self.params_history['sigma'].append(self.sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def to_numpy(params):\n",
    "    return np.hstack([mk.numpy() for mk in params])\n",
    "\n",
    "def set_state(array):\n",
    "    \n",
    "    dims=[]\n",
    "    for a in mover_hmc.kernel_params:\n",
    "        if tf.rank(a)==0:\n",
    "            dims.append(1)\n",
    "        else:\n",
    "            dims.append(a.shape[0])\n",
    "    dims=np.cumsum(dims)[:-1]\n",
    "    for a, b in zip(np.split(array,dims), mover_hmc.kernel_params):\n",
    "        b.assign(a.squeeze())\n",
    "    return\n",
    "    \n",
    "    \n",
    "def drift(x):\n",
    "    delta = 1000\n",
    "    set_state(x)\n",
    "    \n",
    "    with tf.GradientTape() as t:\n",
    "        logpdf = mover_hmc.log_posterior(*mover_hmc.kernel_params)\n",
    "    \n",
    "    gradients = t.gradient(logpdf, mover_hmc.kernel_params)\n",
    "    grad_log_pdf_x = to_numpy(gradients)\n",
    "    \n",
    "    \n",
    "    return delta * grad_log_pdf_x / max(delta, np.linalg.norm(grad_log_pdf_x))\n",
    "\n",
    "def log_pdf(x):\n",
    "    set_state(x)\n",
    "    return mover_hmc.log_posterior(*mover_hmc.kernel_params).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial_state= to_numpy(mover.kernel_params)\n",
    "opt_params = [i.numpy() for i in  mover.kernel_params]\n",
    "opt_ls_v = opt_params[1]\n",
    "opt_amp_v = opt_params[4]\n",
    "    \n",
    "initial_state=np.hstack([opt_ls_v,opt_amp_v])\n",
    "\n",
    "adapt_t_mala_model = AdaptiveMALA(drift=drift,\n",
    "                                    log_pdf=log_pdf, \n",
    "                                    state= initial_state,\n",
    "                                    sigma_0=1,\n",
    "                                    threshold_start_estimate=500,\n",
    "                                    threshold_use_estimate=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "amala_samples = adapt_t_mala_model.run_sampler(500,20000,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pamala_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims=[]\n",
    "for a in mover_hmc.kernel_params:\n",
    "    if tf.rank(a)==0:\n",
    "        dims.append(1)\n",
    "    else:\n",
    "        dims.append(a.shape[0])\n",
    "dims=np.cumsum(dims)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples2 = [tf.convert_to_tensor(a,dtype=tf.float64) for a in np.split(amala_samples,dims,axis=-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_state(init_cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_cond = to_numpy(mover.kernel_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mover.kernel_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lengths = mover_hmc.get_lengthscale()\n",
    "plt.plot(Z,lengths,'o',c='b')\n",
    "Zin = np.linspace(0,24,num=500,endpoint=False).astype(np.float64)[:,None]\n",
    "\n",
    "lengths = mover.get_lengthscale(X=Zin)\n",
    "plt.plot(Zin,lengths)\n",
    "plt.show()\n",
    "\n",
    "amps = mover_hmc.get_amplitude()\n",
    "plt.plot(Z,amps,'o',c='b')\n",
    "Zin = np.linspace(0,24,num=500,endpoint=False).astype(np.float64)[:,None]\n",
    "amps = mover.get_amplitude(X=Zin)\n",
    "plt.plot(Zin,amps)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params = [i.numpy() for i in  mover.kernel_params]\n",
    "\n",
    "with open('opt_params.npy', 'wb') as fp:\n",
    "    pickle.dump(opt_params, fp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('opt_params.npy', 'rb') as fp:\n",
    "    opt_params = pickle.load(fp)\n",
    "    opt_obs_noise = opt_params[0]\n",
    "    opt_ls_v = opt_params[1]\n",
    "    opt_ls_amp = sp_shift(opt_params[2]).numpy()\n",
    "    opt_ls_ls = sp_shift(opt_params[3]).numpy()\n",
    "    opt_amp_v = opt_params[4]\n",
    "    opt_amp_amp = sp_shift(opt_params[5]).numpy()\n",
    "    opt_amp_ls = sp_shift(opt_params[6]).numpy()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,T,ID = setup_data(skip_i=1,skip=2)\n",
    "X[:,0] = X[:,0]-X[:,0].mean()\n",
    "X[:,1] = X[:,1]-X[:,1].mean()\n",
    "X[:,0] = X[:,0]/1000\n",
    "X[:,1] = X[:,1]/1000\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ls_periodic_kernel():\n",
    "    # periodic kernel with single variable parameter. Other parameters are set \n",
    "    # to encode daily activity pattern (period=rescale).\n",
    "    # 15 minute correlation time\n",
    "    return tfp.math.psd_kernels.ExpSinSquared(np.float64(opt_ls_amp),np.float64(opt_ls_ls),np.float64(24.0))\n",
    "\n",
    "def amp_periodic_kernel():\n",
    "    # periodic kernel with single variable parameter. Other parameters are set \n",
    "    # to encode daily activity pattern (period=rescale).\n",
    "    # 15 minute correlation time\n",
    "    return tfp.math.psd_kernels.ExpSinSquared(np.float64(opt_amp_amp),np.float64(opt_amp_ls),np.float64(24.0))\n",
    "\n",
    "\n",
    "# transform for parameter to ensure positive\n",
    "transforms=[] \n",
    "\n",
    "# prior distribution on parameters - changed to 20 \n",
    "lpriors =[]#tfd.Normal(loc = np.float64(opt_ls_mean),scale=np.float64(10))]\n",
    "apriors =[]#tfd.Normal(loc = np.float64(opt_amp_mean),scale=np.float64(10))]\n",
    "\n",
    "# random initial values of mean and kernel amplitude\n",
    "lparams_init =[]\n",
    "aparams_init = []\n",
    "\n",
    "# create the model \n",
    "\n",
    "\n",
    "mover_hmc = moveNS(T,X,Z, ID, BATCH_SIZE=1000, MIN_REMAIN= 500, velocity=True, std_obs_noise=0, mean_obs_noise=opt_obs_noise,\n",
    "                        akernel=amp_periodic_kernel, \n",
    "                        aparams_init=aparams_init, \n",
    "                        apriors=apriors, \n",
    "                        atransforms=transforms,\n",
    "                        lkernel=ls_periodic_kernel, \n",
    "                        lparams_init=lparams_init, \n",
    "                        lpriors=lpriors, \n",
    "                        ltransforms=transforms)\n",
    "\n",
    "mover_hmc.kernel_params[0].assign(opt_ls_v)\n",
    "mover_hmc.kernel_params[1].assign(opt_amp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "learning_rate = tf.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-3,\n",
    "    decay_steps=50,\n",
    "    decay_rate=0.99,\n",
    "    staircase=True)\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate,beta_2=0.99)\n",
    "train_steps = 100\n",
    "pbar = tqdm(range(train_steps))\n",
    "loss_history = np.zeros((train_steps))\n",
    "for i in pbar:\n",
    "    with tf.GradientTape() as t:\n",
    "        loss = -mover_hmc.log_posterior(*mover_hmc.kernel_params)\n",
    "    loss_history[i] = loss.numpy()\n",
    "    pbar.set_description(\"Loss %f\" % (loss_history[i]))\n",
    "    #pbar.set_description(\"Loss %f %f\" % (loss_history[i],gradients[1].numpy()[0]))\n",
    "\n",
    "    gradients = t.gradient(loss, mover_hmc.kernel_params)\n",
    "    optimizer.apply_gradients(zip(gradients, mover_hmc.kernel_params))\n",
    "#n=3.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = mover_hmc.get_lengthscale()\n",
    "plt.plot(Z,lengths,'o',c='b')\n",
    "Zin = np.linspace(0,24,num=500,endpoint=False).astype(np.float64)[:,None]\n",
    "\n",
    "lengths = mover_hmc.get_lengthscale(X=Zin)\n",
    "plt.plot(Zin,lengths)\n",
    "plt.show()\n",
    "\n",
    "amps = mover_hmc.get_amplitude()\n",
    "plt.plot(Z,amps,'o',c='b')\n",
    "Zin = np.linspace(0,24,num=500,endpoint=False).astype(np.float64)[:,None]\n",
    "amps = mover_hmc.get_amplitude(X=Zin)\n",
    "plt.plot(Zin,amps)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def log_normal_pdf_unn(x, mean, variance, inv_variance=None):\n",
    "    \"\"\"\n",
    "    log of unnormalized pdf of a normal distribution.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x\n",
    "        Where to evaluate the Normal.\n",
    "    mean, variance:\n",
    "        parameters of the gaussian.\n",
    "    inv_variance\n",
    "        Inverse of the variance (to avoid computing it again and again in certain cases).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float: the result.\n",
    "    \"\"\"\n",
    "    if inv_variance is None:\n",
    "        inv_variance = np.linalg.inv(variance)\n",
    "    return -1 / 2 * (x - mean) @ (inv_variance @ (x - mean))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def projection_operators(epsilon_1, A_1):\n",
    "    \"\"\"\n",
    "    Return the projection functions defined in the article.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    epsilon_1, A_1:\n",
    "        The two scaling operators.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    proj_sigma: Projection on segment epsilon_1, A_1\n",
    "    proj_gamma: Projection on cone of definite matrix of norm < 1_1\n",
    "    proj_mu: Projection on centered ball of radius A_1\n",
    "    \"\"\"\n",
    "\n",
    "    def proj_sigma(x: float) -> float:\n",
    "        if x < epsilon_1:\n",
    "            return epsilon_1\n",
    "        elif x > A_1:\n",
    "            return A_1\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def proj_gamma(x: np.ndarray) -> np.ndarray:\n",
    "        assert x.ndim == 2\n",
    "        norm = np.linalg.norm(x, ord='fro')  # Frobenius norm\n",
    "        if norm > A_1:\n",
    "            print(f\"Projection on Gamma! norm={norm:.1e}\")\n",
    "            return A_1 / norm * x\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def proj_mu(x: np.ndarray) -> np.ndarray:\n",
    "        assert x.ndim == 1\n",
    "        norm = np.linalg.norm(x, ord=2)\n",
    "        if norm > A_1:\n",
    "            print(f\"Projection on mu! norm={norm:.1e}\")\n",
    "            return A_1 / norm * x\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    return proj_sigma, proj_gamma, proj_mu\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "class AdaptiveMALA():\n",
    "    def __init__(self, state, log_pdf,\n",
    "                 drift,\n",
    "                 epsilon_1=1e-5,\n",
    "                 epsilon_2=1e-6,\n",
    "                 A_1=1e7,\n",
    "                 tau_bar=0.574,\n",
    "                 mu_0=None,\n",
    "                 gamma_0=None,\n",
    "                 sigma_0=1,\n",
    "                 robbins_monroe=10,\n",
    "                 threshold_start_estimate=100,\n",
    "                 threshold_use_estimate=200,\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        Adaptative MALA sampler, described in [1].\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        state: initial state to start in.\n",
    "        pi: Callable. Unnormalized pdf of the distribution we want to approximate.\n",
    "        log_pi: log of the distribution we want to approximate\n",
    "        drift: Callable.\n",
    "        epsilon_1, epsilon_2, A_1: parameters of the HM algorithm. Must verify: 0 < epsilon_1 < A_1, 0 < epsilon_2.\n",
    "        tau_bar: target optimal acceptation rate.\n",
    "        mu_0, gamma_0, sigma_0: initial values for the parameters.\n",
    "        robbins_monroe: constant c_0 for the robbins monroe coefficients: g_n = c_0/n\n",
    "        threshold_use_estimate: int corresponding to the number of steps after which we start updating the covariance\n",
    "        matrix\n",
    "\n",
    "        References\n",
    "        ----------\n",
    "        [1] An adaptive version for the Metropolis adjusted Langevin algorithm with a truncated drift, Yves F. Atchadé\n",
    "\n",
    "        \"\"\"\n",
    "        #super(AdaptiveMALA, self).__init__(state, pi, log_pi, drift, tau_bar, gamma_0, sigma_0, epsilon_2,\n",
    "                                           #robbins_monroe)\n",
    "        #super(AdaptiveMALA, self).__init__(state, pi, log_pi)\n",
    "        self.dims = state.shape[0]\n",
    "        self.state = state\n",
    "        self.log_pdf = log_pdf\n",
    "        self.acceptance_rate = 0\n",
    "        self.steps = 0\n",
    "        self.history = {'state': [state], 'acceptance rate': []}\n",
    "\n",
    "        if mu_0 is None:\n",
    "            mu_0 = state\n",
    "        if gamma_0 is None:\n",
    "            gamma_0 = np.eye(self.dims)\n",
    "\n",
    "        self.drift = drift\n",
    "        self.tau_bar = tau_bar\n",
    "        self.gamma = gamma_0\n",
    "        self.sigma = sigma_0\n",
    "        self.A_1 = A_1\n",
    "        self.epsilon_1 = epsilon_1\n",
    "        self.epsilon_2 = epsilon_2\n",
    "        self.c_0 = robbins_monroe\n",
    "        self._gamma_estimate = self.gamma.copy()\n",
    "        self.params_history = {'gamma': [gamma_0.copy()],'sigma': [sigma_0]}\n",
    "\n",
    "\n",
    "        self.epsilon_1 = epsilon_1\n",
    "\n",
    "        self.mu = mu_0\n",
    "        self.proj_sigma, self.proj_gamma, self.proj_mu = projection_operators(epsilon_1, A_1)\n",
    "        self.threshold_use_estimate = threshold_use_estimate\n",
    "        self.threshold_start_estimate = threshold_start_estimate\n",
    "        self.params_history['mu'] = [mu_0.copy()]\n",
    "\n",
    "    \n",
    "    def run_sampler(self,n_samples, n_burn, thin=1):\n",
    "        \"\"\"\n",
    "        Draw samples from the chain.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        The new state.\n",
    "        \"\"\"\n",
    "        self.steps = 0\n",
    "        \n",
    "        samples = np.zeros((n_samples,self.dims))\n",
    "        \n",
    "        # total iterations for number of samples\n",
    "        iters = (n_samples * thin) + n_burn\n",
    "        \n",
    "        \n",
    "        pbar = tqdm(range(iters))\n",
    "        self.state_log_pdf = self.log_pdf(self.state)\n",
    "        self.state_drift = self.drift(self.state)\n",
    "        for i in pbar:\n",
    "            self.steps += 1\n",
    "            self.proposal = self.proposal_sampler()\n",
    "            self.proposal_log_pdf = self.log_pdf(self.proposal)\n",
    "            self.proposal_drift = self.drift(self.proposal)\n",
    "\n",
    "            alpha = self.acceptance_ratio()\n",
    "            \n",
    "            u = np.random.uniform(0, 1)\n",
    "            if u <= alpha:\n",
    "                self.state = self.proposal\n",
    "                self.acceptance_rate = ((self.steps - 1) * self.acceptance_rate + 1) / self.steps\n",
    "                self.state_log_pdf = self.proposal_log_pdf.copy()\n",
    "                self.state_drift = self.proposal_drift.copy()\n",
    "\n",
    "            else:\n",
    "                self.acceptance_rate = ((self.steps - 1) * self.acceptance_rate) / self.steps\n",
    "            pbar.set_description(\"AR %f SS %f\" % (self.acceptance_rate,self.sigma))\n",
    "\n",
    "            self.history['state'].append(self.state.copy())\n",
    "            self.history['acceptance rate'].append(self.acceptance_rate)\n",
    "\n",
    "            #print(self.state[0])\n",
    "            if i >= n_burn and i % thin == 0:\n",
    "                samples[(i - n_burn) // thin] = self.state\n",
    "\n",
    "            #if i < n_burn:\n",
    "            self.update_params(alpha=alpha)\n",
    "            assert np.isfinite(self.state).all()\n",
    "            assert np.isfinite(self.gamma).all()\n",
    "\n",
    "        return samples\n",
    "    \n",
    "\n",
    "    \n",
    "    def acceptance_ratio(self):\n",
    "        \"\"\"\n",
    "        Compute the alpha parameter for the proposal, given the state we are in (self.state).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        proposal\n",
    "            The proposal value, given by e.g. proposal_sampler()\n",
    "        log\n",
    "            Computing acceptance_ratio using log trick\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A float between 0 and 1.\n",
    "        \"\"\"\n",
    "        \n",
    "        arg_exp = self.proposal_log_pdf - self.state_log_pdf \\\n",
    "                  + self.fwd_log_proposal_value() - self.bkwd_log_proposal_value()\n",
    "        #arg_exp = arg_exp.numpy()\n",
    "        if np.isfinite(arg_exp):\n",
    "            alpha = np.exp(min(0, arg_exp))\n",
    "        else:\n",
    "            alpha=0\n",
    "        \n",
    "        return alpha\n",
    "    \n",
    "    def proposal_sampler(self) -> np.ndarray:\n",
    "        big_lambda = self.gamma + self.epsilon_2 * np.eye(self.dims)\n",
    "        mean = self.state + self.sigma ** 2 / 2 * big_lambda @ self.state_drift\n",
    "        variance = self.sigma ** 2 * big_lambda\n",
    "        sample = np.random.multivariate_normal(mean=mean, cov=variance)\n",
    "        return sample\n",
    "\n",
    "    def fwd_log_proposal_value(self):\n",
    "        big_lambda = self.gamma + self.epsilon_2 * np.eye(self.dims)\n",
    "        mean = self.proposal + self.sigma ** 2 / 2 * big_lambda @ self.proposal_drift\n",
    "        variance = self.sigma ** 2 * big_lambda\n",
    "        value = log_normal_pdf_unn(self.state, mean, variance)\n",
    "        return value\n",
    "\n",
    "    def bkwd_log_proposal_value(self):\n",
    "        big_lambda = self.gamma + self.epsilon_2 * np.eye(self.dims)\n",
    "        mean = self.state + self.sigma ** 2 / 2 * big_lambda @ self.state_drift\n",
    "        variance = self.sigma ** 2 * big_lambda\n",
    "        value = log_normal_pdf_unn(self.proposal, mean, variance)\n",
    "        return value\n",
    "    \n",
    "    def log_proposal_value(self, x, y):\n",
    "        big_lambda = self.gamma + self.epsilon_2 * np.eye(self.dims)\n",
    "        mean = x + self.sigma ** 2 / 2 * big_lambda @ self.drift(x)\n",
    "        variance = self.sigma ** 2 * big_lambda\n",
    "        value = log_normal_pdf_unn(y, mean, variance)\n",
    "        return value\n",
    "\n",
    "\n",
    "    def update_params(self, alpha):\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model: instance of AdaptiveMALA or AdaptiveSymmetricRW\n",
    "        alpha: the acceptance ratio\n",
    "\n",
    "        Updates the parameters of the instance.\n",
    "        \"\"\"\n",
    "        coeff = self.c_0 / self.steps\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        # _gamma_estimate holds the estimation of the covariance matrix.\n",
    "        # It is different from gamma: indeed, we want to estimate the covariance matrix without using it at first.\n",
    "        if self.steps > self.threshold_start_estimate:\n",
    "            coeff_gamma = self.c_0 / (self.steps - self.threshold_start_estimate)\n",
    "            covariance = (self.state - self.mu)[:, np.newaxis] @ (self.state - self.mu)[np.newaxis, :]\n",
    "            #covariance = np.diag((self.state - self.mu)**2)\n",
    "\n",
    "            self._gamma_estimate = self.proj_gamma(self._gamma_estimate + coeff_gamma * (covariance - self._gamma_estimate))\n",
    "        if self.steps > self.threshold_use_estimate:\n",
    "            self.gamma = self._gamma_estimate\n",
    "        \n",
    "        \n",
    "        self.mu = self.proj_mu(self.mu + coeff * (self.state - self.mu))\n",
    "\n",
    "        self.params_history['gamma'].append(self.gamma.copy())\n",
    "        self.params_history['mu'].append(self.mu.copy())\n",
    "\n",
    "        \n",
    "        self.sigma = self.proj_sigma(self.sigma + coeff * (alpha - self.tau_bar))\n",
    "        self.params_history['sigma'].append(self.sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def to_numpy(params):\n",
    "    return np.hstack([mk.numpy() for mk in params])\n",
    "\n",
    "def set_state(array):\n",
    "    for a, b in zip(np.split(array,[25]), mover_hmc.kernel_params):\n",
    "        b.assign(a)\n",
    "    return\n",
    "    \n",
    "    \n",
    "def drift(x):\n",
    "    delta = 1000\n",
    "    set_state(x)\n",
    "    \n",
    "    with tf.GradientTape() as t:\n",
    "        logpdf = mover_hmc.log_posterior(*mover_hmc.kernel_params)\n",
    "    \n",
    "    gradients = t.gradient(logpdf, mover_hmc.kernel_params)\n",
    "    grad_log_pdf_x = to_numpy(gradients)\n",
    "    \n",
    "    \n",
    "    return delta * grad_log_pdf_x / max(delta, np.linalg.norm(grad_log_pdf_x))\n",
    "\n",
    "def log_pdf(x):\n",
    "    set_state(x)\n",
    "    return mover_hmc.log_posterior(*mover_hmc.kernel_params).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state=np.hstack([opt_ls_v,opt_amp_v])\n",
    "\n",
    "adapt_t_mala_model = AdaptiveMALA(drift=drift,log_pdf=log_pdf, state= initial_state,sigma_0=1,threshold_start_estimate=100,\n",
    "                 threshold_use_estimate=200,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state=np.hstack([opt_ls_v,opt_amp_v])\n",
    "\n",
    "adapt_t_mala_model = AdaptiveMALA(drift=drift,log_pdf=log_pdf, state= initial_state,sigma_0=1,threshold_start_estimate=100,\n",
    "                 threshold_use_estimate=200,\n",
    "                 )\n",
    "amala_samples = adapt_t_mala_model.run_sampler(5000,10000,1)\n",
    "#amala_samples = adapt_t_mala_model.run_sampler(10,10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.hstack([mk.numpy() for mk in mover.kernel_params])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_t_mala_model.log_proposal_value(p,adapt_t_mala_model.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_t_mala_model.acceptance_ratio(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_exp = adapt_t_mala_model.log_pdf(p) - adapt_t_mala_model.log_pdf(adapt_t_mala_model.state) \\\n",
    "          + adapt_t_mala_model.log_proposal_value(p, adapt_t_mala_model.state) - adapt_t_mala_model.log_proposal_value(adapt_t_mala_model.state, p)\n",
    "arg_exp = arg_exp.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "np.isfinite(arg_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(amala_samples[:,26])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amala_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_t_mala_model.acceptance_ratio(adapt_t_mala_model.proposal_sampler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_t_mala_model._gamma_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples2 = [tf.convert_to_tensor(a[4000:,],dtype=tf.float64) for a in np.split(amala_samples,[25],axis=-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mover_hmc.kernel_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as t:\n",
    "    loss = -mover_hmc.log_posterior(*mover_hmc.kernel_params)\n",
    "    \n",
    "gradients = t.gradient(loss, mover_hmc.kernel_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(to_numpy(gradients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.split(state,[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.stack([tf.expand_dims(a,-1) for a in mover_hmc.kernel_params],axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def build_trainable_location_scale_distribution(initial_loc, initial_scale):\n",
    "    \n",
    "    with tf.name_scope('build_trainable_location_scale_distribution'):\n",
    "        dtype = tf.float64\n",
    "        initial_loc = initial_loc * tf.ones(tf.shape(initial_scale), dtype=dtype)\n",
    "        \n",
    "        initial_scale = initial_scale * tf.ones_like(initial_loc)\n",
    "\n",
    "        loc = tf.Variable(initial_value=initial_loc, name='loc')\n",
    "      \n",
    "        \n",
    "        scale=tfp.util.DeferredTensor(tf.Variable(initial_scale, name='scale'),tf.nn.softplus)\n",
    "\n",
    "        posterior_dist = tfd.Normal(loc=loc, scale=scale)\n",
    "\n",
    "        \n",
    "        posterior_dist = tfd.Independent(posterior_dist)\n",
    "        \n",
    "    return posterior_dist\n",
    "\n",
    "\n",
    "flat_component_dists = []\n",
    "\n",
    "\n",
    "init_loc = mover_hmc.kernel_params[0]\n",
    "init_scale = tf.random.uniform(shape=mover_hmc.kernel_params[0].shape, minval=-2, maxval=2, dtype=tf.dtypes.float64)\n",
    "\n",
    "    \n",
    "flat_component_dists.append(build_trainable_location_scale_distribution(init_loc,init_scale))\n",
    "\n",
    "\n",
    "init_loc = mover_hmc.kernel_params[1]\n",
    "init_scale = tf.random.uniform(shape=mover_hmc.kernel_params[1].shape, minval=-2, maxval=2, dtype=tf.dtypes.float64)\n",
    "\n",
    "    \n",
    "flat_component_dists.append(build_trainable_location_scale_distribution(init_loc,init_scale))\n",
    "\n",
    "surrogate_posterior = tfd.JointDistributionSequential(flat_component_dists)\n",
    "\n",
    "\n",
    "\n",
    "def target_log_prob_fn(*inputs):\n",
    "    #params = []\n",
    "    #print(inputs)\n",
    "    #print('----------')\n",
    "    #params.append(mover_hmc.kernel_params[0])\n",
    "    #params.append(mover_hmc.kernel_params[1])\n",
    "    params = [tf.squeeze(a) for a in inputs]\n",
    "    loss = mover_hmc.log_posterior(*params)\n",
    "    \n",
    "    #print(loss)\n",
    "    return loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def build_trainable_location_scale_distribution(initial_loc, initial_scale):\n",
    "    \n",
    "#     with tf.name_scope('build_trainable_location_scale_distribution'):\n",
    "#         dtype = tf.float64\n",
    "#         initial_loc = initial_loc * tf.ones(tf.shape(initial_scale), dtype=dtype)\n",
    "        \n",
    "#         initial_scale = initial_scale * tf.ones_like(initial_loc)\n",
    "\n",
    "#         loc = tf.Variable(initial_value=initial_loc, name='loc')\n",
    "      \n",
    "        \n",
    "#         scale=tfp.util.DeferredTensor(tf.Variable(initial_scale, name='scale'),tf.nn.softplus)\n",
    "\n",
    "#         posterior_dist = tfd.MultivariateNormalTriL(loc=loc, scale_tril=scale)\n",
    "\n",
    "        \n",
    "#         posterior_dist = tfd.Independent(posterior_dist)\n",
    "        \n",
    "#     return posterior_dist\n",
    "\n",
    "\n",
    "# flat_component_dists = []\n",
    "\n",
    "\n",
    "# init_loc = mover_hmc.kernel_params[0]\n",
    "# init_scale = tf.random.uniform(shape=(mover_hmc.kernel_params[0].shape[0],mover_hmc.kernel_params[0].shape[0]), minval=-2, maxval=2, dtype=tf.dtypes.float64)\n",
    "\n",
    "    \n",
    "# flat_component_dists.append(build_trainable_location_scale_distribution(init_loc,init_scale))\n",
    "\n",
    "\n",
    "# init_loc = mover_hmc.kernel_params[1]\n",
    "# init_scale = tf.random.uniform(shape=(mover_hmc.kernel_params[1].shape[0],mover_hmc.kernel_params[1].shape[0]), minval=-2, maxval=2, dtype=tf.dtypes.float64)\n",
    "\n",
    "    \n",
    "# flat_component_dists.append(build_trainable_location_scale_distribution(init_loc,init_scale))\n",
    "\n",
    "# surrogate_posterior = tfd.JointDistributionSequential(flat_component_dists)\n",
    "\n",
    "\n",
    "\n",
    "# def target_log_prob_fn(*inputs):\n",
    "#     #params = []\n",
    "#     #print(inputs)\n",
    "#     #print('----------')\n",
    "#     #params.append(mover_hmc.kernel_params[0])\n",
    "#     #params.append(mover_hmc.kernel_params[1])\n",
    "#     params = [tf.squeeze(a) for a in inputs]\n",
    "#     loss = mover_hmc.log_posterior(*params)\n",
    "    \n",
    "#     #print(loss)\n",
    "#     return loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate_posterior.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mover_hmc.kernel_params[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "start = time.time()\n",
    "losses = tfp.vi.fit_surrogate_posterior(\n",
    "    target_log_prob_fn, surrogate_posterior,\n",
    "    optimizer=tf.optimizers.Adam(\n",
    "        learning_rate=0.1,\n",
    "        # Decay second-moment estimates to aid optimizing scale parameters.\n",
    "        beta_2=0.9),\n",
    "    num_steps=5000)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = surrogate_posterior.sample(10000)\n",
    "sp_np = [s.numpy() for s in sp]\n",
    "\n",
    "opt_step_size = [np.std(sp,axis=0) for sp in sp_np]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opt_step_size = [np.min(oss,0.1) for oss in opt_step_size]\n",
    "#opt_step_size[0][opt_step_size[0]>0.1]=0.1\n",
    "#opt_step_size[1][opt_step_size[1]>0.1]=0.1\n",
    "\n",
    "plt.plot(opt_step_size[0])\n",
    "plt.plot(opt_step_size[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5e-2**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples=1000\n",
    "burn=1000#250\n",
    "mover_hmc.num_samples = num_samples\n",
    "\n",
    "#v=0.15\n",
    "#s=1\n",
    "\n",
    "def volatility_fn(*x):\n",
    "  # Stack the input tensors together\n",
    "  #return [1. / (0.5 + 0.1 * tf.math.abs(y)) for y in x]\n",
    "    #return [1 for vv in opt_step_size]\n",
    "    return [(vv) for vv in opt_step_size]\n",
    "\n",
    "\n",
    "ss=np.float64(5)\n",
    "step_size = [ss for a in opt_step_size]\n",
    "inner_kernel = tfp.mcmc.HamiltonianMonteCarlo(target_log_prob_fn=mover_hmc.log_posterior, step_size=bb, num_leapfrog_steps=3)#max_tree_depth=4)\n",
    "#inner_kernel = tfp.mcmc.MetropolisAdjustedLangevinAlgorithm(target_log_prob_fn=mover_hmc.log_posterior,step_size=step_size,volatility_fn=volatility_fn)\n",
    "#)#, step_size=steps)#max_tree_depth=4)\n",
    "kernel = tfp.mcmc.DualAveragingStepSizeAdaptation(inner_kernel, num_adaptation_steps=int(burn * 0.8))\n",
    "start = time.time()\n",
    "\n",
    "samples, kernel_results = tfp.mcmc.sample_chain(num_results=num_samples, num_burnin_steps=burn, num_steps_between_results=0, current_state=mover_hmc.kernel_params, kernel=kernel)\n",
    "end = time.time()\n",
    "\n",
    "print(end - start)\n",
    "mover_hmc.samples_ = samples\n",
    "print(np.sum(kernel_results.inner_results.is_accepted.numpy()/num_samples))\n",
    "tfp.mcmc.effective_sample_size(samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(end - start)\n",
    "mover_hmc.samples_ = samples\n",
    "print(np.sum(kernel_results.inner_results.is_accepted.numpy()/num_samples))\n",
    "tfp.mcmc.effective_sample_size(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_results.inner_results.is_accepted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print((end - start)/60)\n",
    "mover_hmc.num_samples = 500\n",
    "mover_hmc.samples_ = samples2\n",
    "#print(np.sum(kernel_results.is_accepted.numpy()/num_samples))\n",
    "tfp.mcmc.effective_sample_size(samples2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((end - start)/60)\n",
    "mover_hmc.num_samples = 2000\n",
    "mover_hmc.samples_ = samples2\n",
    "print(np.sum(kernel_results.is_accepted.numpy()/num_samples))\n",
    "tfp.mcmc.effective_sample_size(samples2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "50*676/60/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(samples2[0][:,])\n",
    "plt.show()\n",
    "plt.plot(samples2[0][:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAFhCAYAAABtfJ6IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAABH8klEQVR4nO3deZRc533e+e/daq/q6r3R2AiQYBFcRVFbZNmyNjuxrIydOJ54MlacxMkkJ4sceSQnI2fzNidn4pOMz4wnlpOZZDLyjB3HtrwqiSxZC7USJCUuzQJI7Gj03tVVXevd5o9qoOs20ECTQKO253MODvt961bV+6LB6qfvfe/vNcIwRERERERuzez2AERERET6gUKTiIiIyB4oNImIiIjsgUKTiIiIyB4oNImIiIjsgUKTiIiIyB7Y+/0Gp06dUk0DERER6RtPPfWUcbP+fQ9NW2++r68/NzfHyZMn9/U9etkwz3+Y5w6a/zDPf5jnDsM9/2GeO+z//E+dOrXrY7o8JyIiIrIHCk0iIiIie6DQJCIiIrIHCk0iIiIie6DQJCIiIrIHCk0iIiIie6DQJCIiIrIHCk0iIiIie6DQJCIiIrIHCk0iIiIie6DQJCIiIrIHCk0iIiIie3BPNuwVEekXQRgShmAaYBg33ehcRIaUzjSJiGzxgoAwbH/thyHhtYaICApNIiJA+wxTEIaEtIOSaRj4Ck0i0kGX50REAM8P8IOAht8+2xRzTBzLIghDTF2mExF0pklEhCAMcf2AhhdgGia2aVBrBbieT6CzTSKyRaFJRIaeFwQ0PR8jDPGDENcLMMKAWssn1NomEdmi0CQiQy0MQ5quh+eHhIZBzDFJJxxM06LlBtRbHoEyk4ig0CQiQy4IQ+puQBCExG0L3w/ZbLj4YYhp+tTqrs40iQigheAiMuRaXoDreiRjNq4XsFFrYRoBIQYQgmFSd13SZkwLwkWGnEKTiAw11/cIQ7BNg8VyFdeDgAA3CCAIScdtLMsgGdNddCLD7pahqVAoPAp8HFgHisVi8Zc7HhsHvgb8lWKx+OV9HaWIyD4IgoC6F+JYFuW6x2bDxTIM0gkH2wtZqTXxfB8TcOMWdiLe7SGLSBfdbk3TR4FPFIvFjwDfXygUDICt//4c8Ef7PD4RkX0TAI2mh20ErFZrlJstys0Wl9dqzK9WCQOXlWqDasOjHoQqPyAy5G4XmmaBy1tfl4Cxra8/BvxbYG1/hiUisv/qrkdIu6BltepRqTSoNFqEgYdvhCyWPRq1FlfLVSr1FspMIsPNuNVdIYVC4d8A/6xYLF4qFAqfAf4MEAf+HfAK8N3AWeDHi8VicLPXOHXqVJhKpe7ysKMajQaJRGJf36OXDfP8h3nuoPnf6fzXag1ank/d9Xl1sUrgQSoOMRtCE9ar0PAgEYejeZsTk2M4tnUXZ/DG6Xs/vPMf5rnD/s+/Vqvx1FNP3XQB4+0Wgv8i8POFQqEE/Bbwq8Vi8ceBvwhQKBT+KfDZ3QLTNSdPnny9Y35d5ubm9v09etkwz3+Y5w6a/53MPwgCrm40IHQ5s1giF9aww4BY3CJhWGAZpOpNFmp1nNDDyU9y6Ngso+kERg8sCNf3fnjnP8xzh/2f/6lTp3Z97JahqVgszgEf7uj65I7H/+mdDExEpFsCaG+Tgkdp06XeqhHHoOGGtCyb0LJp1Ddxm01qXkhqo0al1iKfTtD9yCQi3aDiliIylFzXJwwDWg1YKpcJmy5r9QarzRaNwKLpu6zWfRquz2bTZ6m8zoWVNQKVBxcZWqrTJCJDqRn4BIbBcrXOZt2j2mpQbwXk0za25WOZMRyrymIpxKtBEHpcWa3RaLXIJId3PYnIMNOZJhEZSo1GAIHHUrlKgwaVWkCjCR4GrWaD0G+Qsh2SZnsx+No6nF9dY6Pe1LYqIkNKoUlEhk4YhjSDAM/3WSpVqG14lDbAd6HVcNslCDyoeT6GAb4JlSqs1lzOLZdQZBIZTgpNIjJ0gjDE93zqDY9Sw6XahEYTao32h+JIJkUmZmGa0AwBDzaB9VW4uFLB8/wuz0BEukGhSUSGTsv1CEJYqdSo1euslsDzwXZgJJPEwcQ0bWI2uD4EPtSBhQYU55cp1xrdnoKIdIFCk4gMnaYfEBCyUq5RrkPLhzKQToGHz2bDJRVzGIllyMXAM9p3zdSAK2shV8sVrWsSGUIKTSIydFpeSBC4LG02qG9ChfZWB3ELKjWf0IBS3aPsNkmmTJJm+8OyCpTKcHZxQ/vQiQwhhSYRGTquH1BruVSaDTbq7fVKaRtKdfADnyDwcZsN6q0WzWaAaYEFhMAF4IVLS7ha1yQydBSaRGSohGGI6we0mh7LZZcNwACsEFotSMfAMOMkEia2ZVBugedGPywvLnmsVSpdmoGIdItCk4gMlSAMcT2P9WqDchkatENT0wcnhDBMsFJeY369huca0IKaB27HayyW4fzyepdmICLdotAkIkPF9TzAZLlUYbPeXqeUoH13XCILSxsNqs0AgxAPD8eCJu11T7Gt15gHXrm6hh/ccq9yERkwCk0iMlSafoAfBixs1qlv9YW01yx5FVhfB7cFgekRGu0yBEnAB1odr/PqQoWm693r4YtIFyk0ichQafkh9XqdSq3F4lZfADjAShWCEJIxmE1mOJDJEItb2HBDFfDTl6FcVb0mkWGiDXtFZKi4bkAjcFnd3A5C7Qt27Ut1kyZMZOPkRnKMpDOk4wYbm6vYy9F1TReAV+YXmB7NYhjGvZ6GiHSBzjSJyFBx/YBGw6W0Yx13hfbapfQYTOTHmM2nySZNRtPjPDiTZPImr/XC5UU8X6UHRIaFQpOIDI0wDGl5HotrZVY6+pu01yvZwHTKYiafZmIkxZGxDAfHExwaneTITVLTS6+5tLQYXGRoKDSJyNDwgwDPCyhVGpQ6+m1gDZhKwMGJPJOZBCPJODHbZiybYnYyzYnZFOkdr/dCDcqVOiIyHBSaRGRo+L6PgcFCpRFZ2N2ivb4pHYeJ3AhjI0lScZtU3CJu20zm0hyfOMCJZPT1WkDxylXtQycyJBSaRGRoNPyAhu+yvBHt94AMcHjGYTwbZzyTIBVziNs2uaTDSCrBzIjDAwdvfM1vX5xXvSaRIaHQJCJDww1CavUmldqNj00BB0bHODiWJuk41/sNwyCTsJkcTfPA1AHGdzzv+VfBVWgSGQoKTSIyNFwXym6TlZvUpBxNQS6TZGZk58olsEyTsUyKwzMjPLIjNb3kQrl6kxQmIgNHoUlEhkbL82g2PVZv8tjEGBwZy2Bb1k2fm3BsZsey3H8wE+kPgHNLa1rXJDIEFJpEZCiEYUgQhlyeX2TnxbQ0MDk6wqHR5M2eCrQv042nExw7NEF+x2Nfe+mc1jWJDAGFJhEZGq2Wy1r9xnCTAqazCcYyN16a65RwbI7kMrxlNtr/7Kvt9VIiMtgUmkRkKHi+jxeGrG7e+NikA8emRjHNW38kGobBwfEMD0znIv1zQK2mek0ig06hSUSGQsv1cL2A9Y0bHzs4AzP5xJ5eJxuP88DsxA2FLi8sr2pdk8iAU2gSkaHQCqHaaLJyk63iJnI5ZnK3vjR3jWVZHJ4Y5cmJaP+pM1rXJDLoFJpEZCh4QUi5XovsOQeQBA7lE8Tj8T2/1lQ2zqOH85G+L78Y4ikziQw0hSYRGQotN6DuejfcOTcKHJ0YfV2vlU7EuX8m+pyXgWardUdjFJHeptAkIkOh5QdcWVy8oX8yCRMjez/LBO0F4ffPTnBiR/+VlRWtaxIZYApNIjIUAt9nvXJj/6EDMJHe2yLwThPpGG8+GYv0PfvqRQKFJpGBpdAkIgMvCAJ8L2DtJuUGxrMjZJK7F7XcTSIW4+TByUjfF59v4voKTSKDSqFJRAZeEIbUPJfFm5QbOJSJYe2ydcqtGIZB4cAknZuqPBdAo9l84wMVkZ6m0CQiA8/1PAI/vGHPuVHg6NTYG37dmZEkT+54+kq5rHVNIgNKoUlEBp4fhFRqDXaeaBo3YGLk9V+auyYVj/O2wnik7+tzZ7WuSWRAKTSJyMBzQyg3GjeUG5gch3zq9d0518k0TU4ejFa5/PpcA0/rmkQGkkKTiAy8lhdQqVZv6D8w6pBOvP475zodnshzuKP91To0XPeOXlNEepNCk4gMvKYbcHX1xlXgR8ayb2gReKdMIsZTh6N9y+slrWsSGUAKTSIy8PwgYHH9xv6Do3vbb+5WHNvmbSdmIn3PnbmgdU0iA0ihSUQGnuv67DzRlAYmc5mbHv96GIbBicMHIn1febGKq43oRAaOQpOIDLQgCPDDgGU/2j8OjOVSd+U9pnIpHu/4NH26Dk3fuyuvLSK9Q6FJRAZaGIbUWy7lHf2jGcjE7LvyHsl4jLc+tL02KgSW10p35bVFpHcoNInIQHN9n2qtxc57545MQOoO75y7xjAM3vVYIdL3/KuX8ANdohMZJApNIjLQXD9gs16/oX86n7njO+c6HRjLRtpffbmidU0iA0ahSUQGmheErFdrN/QfHM/d1ffJxmN8T0edy6c3oeFpXZPIIFFoEpGB1vQDShs31huYTd+dReDXOLbNWx7YDmI+cHXlJnUORKRvKTSJyEDzfLi6Y6feMWBsPHvT498owzB404njkb5nz5zH9/1dniEi/UahSUQGWsv1uLLjhE8ayMXvzp1znabyafId7VPFOi3tQycyMBSaRGSg+d6NNZoOZCFu3/3QlIzHeM+R7faXqlBvte76+4hIdyg0icjACoIALwip7OifHINkPH7X388A3lGIbqlyZXHtrr+PiHSHQpOIDKwwDGm6N6vRNIJp3v2PP8MwePTYkUjfqXNa1yQyKBSaRGRg+WHIZvPG2/5nx+58z7nd5BIxDne0nz3Tot5SaBIZBApNIjKw/CCgvHljjaaZTHrf3jMWc3jfye32Vzeh5rn79n4icu8oNInIwGq5Pivr0VvnUsDo6P6FJtMweMeDxyJ9Zy9dJQx1F51Iv1NoEpGB5YewthFd0TQGZO/SRr27efDIbKT9/MUFPO1DJ9L3FJpEZGC1goDLy9G+XAxSjrOv7xu3LE50tJ+Za7HZ0CU6kX6n0CQiA8vzQxY2o30zkxCLxfb1fR3b4nue2n6Pb3mwUavrEp1In1NoEpGB1Wz67KySdHjM2ZdyA50Mw+A7Ttwf6Xvx4jyBQpNIX1NoEpGB5fs+Gzv6Do6P3ZP3npkYjbRfOLdI01PpAZF+ptAkIgMpDEMarsfOTUwmk3e/EvjNpBNx3tlRDuq5c1DarN+T9xaR/aHQJCIDKQgCmt6NhS3HR3L35P0N4ANvn7rePgdcWt3QJTqRPqbQJCIDKQhD1nYUtkwCucy9OdNkGAZPHIruQ3f66gque2OQE5H+oNAkIgMpANY2oiuaxoCkfe8+9qbyI5H2My+vs1HfecFQRPqFQpOIDKRmy2VlKRqashYk7f0tbNnJcWw+1FHn8pkKrG3WdYlOpE8pNInIQAoCWN1x69z0BMTj9+byHLTXNb3vzdvb97aAVxdWcG+y1kpEet8tf+UqFAqPAh8H1oFisVj85a3+HwXeC4TAZ4rF4m/s90BFRF4PNwy5HN12jiPj5r7XaOpkGAYPHZwGLl3ve+niPO84cZj4PlclF5G773afHh8FPlEsFj8CfH+hUDC2+s8DfxX4B8AP7t/wRETeGDcIKe/om8rdmzvnOuVSaY52tJ95FVZrLV2iE+lDt7u4Pwtc3vq6RHsd5WqxWPxSoVD4YeBvA//sdm8yNzd3J2O8rUajse/v0cuGef7DPHfQ/G81/0urG5zb0ddcLd3zv68gDHnTCFzYulR4HvjyqedoHJkiZltv+HX1vR/e+Q/z3KG7879daLoMHKJ9bnkM2jsSFAqF9xaLxd8oFAq/A/wh8LlbvcjJkyfvfKS3MDc3t+/v0cuGef7DPHfQ/G81f/PKGnz1+UjfW9/8KCePTN30+P1kpHN8+jdOX283rQSzR48xkU1hGMYtnrk7fe+Hd/7DPHfY//mfOnVq18dud3nuF4GfLxQKvwT8FvCrW/2PFwqF/w34JPDpuzFIEZG7qelGb+23gEy6O+uIjs1MRtrPzTVYr7YIdIVOpK/c8kxTsVicAz7c0fXJrf5/tY9jEhG5I0EQ0NhRRHIcyDhv/HLYnYg5Md43Dn+82m4/78HSWoXD4xmSMS0IF+kXKjkgIgMnCAI2dlQDTwOJLt2xZhrwwbccivSdWVxgvdbUgnCRPqLQJCIDJwSWStF758azEI/FujIewzB46Mh0pO+5VzYpVV083+/KmETk9VNoEpGB44UhS0vR0DQ7DpbVnctzAPlMhoc72t+swmq5Qr3lEepsk0hfUGgSkYHjeT6Lq9G+6fy9qwR+M5Zl8t2Pbd8p5wHnFhdYq7bwtSJcpC8oNInIwPH9kMVqtG9mdLQ7g9liGgbveix6m/TXXt5ks+7esGhdRHqTQpOIDBzXD26oBj6TTXdlLJ1mx0Y40NF+pgqrlQ1KtabONon0AYUmERk4bhiyvKMvl0l2ZSydkokE731gux0Cp68ssNnytImvSB9QaBKRgdNyPeo7+jLJ7tw518kA3vXI/ZG+b7zcwG26bKj8gEjPU2gSkYHTbAWR9hjdK2zZyTAMThycINPR9y0XFtZLVJsBLa1tEulpCk0iMnCq9WhhyzwQs2+31ea9kUmm+M7D0b5Tr12m6btUGrqTTqSXKTSJyEAJw5ByrRHpy6W6V9hyJ9OA9z92X6Tvy2dhs1Zno+7RclW3SaRXKTSJyEDxfZ+ljei9c4cmu1vYspNhGDx6eIJsR98i8MLZeQLfp1Rv4gXBbk8XkS5SaBKRgRICK6sbkb7pfG9cmrtmJJPl3Tsu0X3t9CYQUncD6q6nReEiPUihSUQGih+GXF2KBo4DI90tbLmTacD7n4zeRfdiHV65sowRBFRqLVztSSfScxSaRGSgBCEsRE80MZ3L3PzgLjEMg5MHRuncwtcFvvHqPAEhDdenUmvpMp1Ij1FoEpGB4nkelR192R4obLnTSCbLe05E+56/DKevrBC3TTZdX5fpRHqMQpOIDBTXC28ITZlkdzfrvRnTgD/1aDQ1LQJfLl6i0fQww5BytUmzpeAk0isUmkRkoLSCgKWOdgLIxXrjzrlOhmHw8IExHk1E++cuw+n5JWK2gRsGbDZdXM9XcBLpAQpNIjJQmi030h4D7B4pN7BTLpXivY9HF6lfAr5YnGdts07KsWm4AdWWgpNIL1BoEpGB0mhFtyIZiUEqkdjl6O4ygLceP8DEjv7z8/DM6Su4XkjMMag128Gp5fl3rWJ4GIYEYYgftP94QXD9z7U+FdkUiVJoEpGBUq5Gt+qdybcvhfUiwzA4OjnK249G+18Dvr20zrnFNUzDJOYY1Fshmw2Xpue94bNO10KS6/u4QYDrB/hhgOv7eL5//b9+EOBfC1F+oK1dRLb0VsU3EZE7EIYhpc1qpG92Ekyzd38/TMRjvPOho/zhhQt0RpMLl+D50auMZZIcGMtixUIaLR8vCEjHbLwgwPV8TNPEMNpnrXYKwpAgbP/32pklQvDDgCA08HyfIDAIjRC2QpgfhBhGiGVYmKaBbYBtmdiWiWWaWKbRsyFUZL8pNInIwAjDkIWNzUhfPpHq0mj2xjAMHjk4ylP5CzxT2u6/ABTnq4xml0jGbEazKbIJk2rTo1Jzqbdcmp6PYQaYmGC0Q08Yhu0EtZWDggAMM8T3Atww5FrppzAMMU2un0XyfY9WEBAE4AU+fgBhAKYNtmFhGxCL2WSTDnHLwjJNTNPAVICSIaLQJCIDww8C1lajBQdmx3urGvjNzIzmeffJWZ756vz1vhBYXIFXc4ukEzZvPjRNNpskm3BwfZ+mG1JueFihj+VY2IYFBhgGhEFAEIIbhPgBWGFIaLQDmmGEWKYJhkm96dL0AxpNn1YQYgUhTa9FSEgrhGbTxTAs3ABySYOEE2Nj0yKbtMmm4ji2hW0aOJal8CRDQaFJRAbK/HK0PRLrzUXgnSzT5MmjYzzx4jzf6sh854D8PGQTayQtk4I5SS6RIOE45JIOuYRF0zfxXZ9q2AIMDNrhyDItTANiDtimRUj7rJMbeNSbPtVGg1ZgYpshNgEhUPE96g2XaqNFs+nR8H3cMMTwfa6EEIunSCcMsk6cXNbhYD7DSDKO6wXEbIuY3Zt3KYrcLQpNIjIwvDBkKbqkiWyu9wpb3szhyRHefCzHC98u07l5yqUGjKzWccw1DNPhvok8+XSclu9jGiapmIEZt69dnQOjfZaqfWopxHU9Gl57E+Bqo4XfAtcKSFk2ju1Tq7Uo1VwqNZfNRo16YOJ5NTAsfMMHP8ALQoLQIqxXCUKDsUyKxGaMpbUGB8aTHBlLAwncICTlWFrzJANLoUlEBobvBzdUA08n+iM0JeMx3vHgIb517mWe7ZjECrC0DCmnSjy2Tr3lc2QsTanRpFJv4jg2Bu3F7teiiut5NF2flhfihiEt1ycMQ2zbJJEKiXsGpUaLxXKNjUqNmudRrdVwCTACEz9o4vsBbgChaWAaIZbfXuPkW9BcbzCSyYLvUW25rFabHJ8cYXokRbUVkrRNrB6tjSVyJxSaRGRgNFs+nXv1JoCs3bt3znUyDIMHp/O8+cQoxWfX6TxhVgwgvgrpxDphGNLyfZqVKgsbFWJ2AsM0sSwDAgjCgCAMMIIA3zCxDQPLDDEMCDyfS+s1FjY2KVdrlGotWs0GXgBNAxrN9lkqPwC/1X5vKwixEuC2wDLBC8AwYWGjwuRInePjaTarcNorUau1ODiRgcAmGUPBSQaOQpOIDAzPj4amEcCx++djLpWI8dbjsxQvrfOljrVZPnCuDslVsO0ayYTDYgnyq3UyyRbZmINlte9wM0MD07ZohCF24FJ3XTbcgOVyk6XSBpVak1rQwmiGbHrg++3Xb1XB9aDZAttq94e0A1JYgUQcjID2nXkxcOuwtuJxdXWDh6ebHJwa5RI+m57HA9MjhGFIMt671dhF3oj++TQREbmNuudH2mNO71YDvxnTNLl/OseTx6e5tLzI+Y7HSsDFdbCsFr5RpVGHWqNGuQpOMo4dQizugGESeh6hDxuNKrWmx1qlhh+G+H6LwIeKB2ELPI92exOaW5UKqoDhQ5P2Hz8ADzAakAIsINNsn8ULgUslWCk1eLBylcePTmOGBsXApDCTAQOSMQUnGRwKTSIyMOqNaDXwyVzvVgPfTTYR5033TfHa4iIr56Gz6tRlILECFjVam5DfbJGyTTzfx7ZCyrUQ3w/bpQbCAM8zaPkNTNNjrRQQGuAGELjQbLZDU9ODerh1WY7rJZ6IA0naQckF6rTDkwcsA5mtxx1gCWjNg9ta5LH7pwgJeW0JTszkwDDImGbffR9EbkahSUQGRrnajLRnZ3q7GvjNmKbJ8ckcbz5+lOW1C7xUbocWDwiAVwF/pR1YSuslahmbFA6YYBs2mAFB6OP7IeV6k2odGn77yb4PDQ+8xlYQcttBCdp7aqWA2NYppIQDtgnVFsR9sN12gLO3xrHc8ZxRYA14fgUa7hJvfWgKx3I4vVjhwakcBgbpuK3gJH1PoUlEBkIYhlwtb0T6JuLJLo3mziTjDo8cGmN+dY3q6Qrn6xCj/YFdAa7QDj3hRZg44OGYHg4QM8A12iHJDcEOwPAAA+p1aDXbj4cu1xeaG2ydMXLAibc77DhYzXY18HwSXBcSPqRa0HQh5rXPRFVoB6kakN36+oUN8F5Y4h2Phkz5Wc4ScvxAHsuDpOPc079HkbtNoUlEBsZGOXp5bnoi352B3CHTNDk0luXRI7NsNl7DfdVjzW9/YGdprzVaAi4BlavtvnSmHXLMra1TzLB9Sc0N2pfifH9rvRLts1YpIG5CPAFJCxwT0tn2GaZk3CFmxzAtEyMIsS0Tj5CNWoNq02WzDKUSJML2WqtNuL4A3wXmasDLy7yt4BMyRtwqcWhiBMswiPXRwnyRnfSvV0QGguf7zC/UIn1jiXSXRnPn4o5NYTZHuXGYWuscZy/Dhtu+JJalfeYpDqzSPuNjbW6vMdo6uUS41Q62/ji0F3Dn02DGwDLASUA2DqmkhRk6JJMZMlZINuOQtuOk4gnCMGzvY+e71L2Qq+trLNYaLF5tkd5oj2F16/1g64zTJtjn1nhzCD6jJOOb2PYIlhlimbpMJ/1JoUlEBsZyOdrOpvv7ctB4Js3JAz71hovHZRaWoLR1Xc0CpvMw7kFogu9Bq9YOTI7dbru0/yQNiMUBG3Kp9lko04a0A8mkRRA42LbNaNxhNJkiHrMxHYuYaWGaJqHRDjoBFrHAIJFyyG3UGYmt4SzUsEoQtNrrmq5pAN9eAye2xlOOyUXHIhGrYRppMlrfJH1KoUlEBsLNtlBJJ/un3MDNmKbJ7FiGTS+gFYbErQWSGz61ClxttM88xUxIOu11SOkseH77Ulyr2X4sDuBANg1xq312yYpZGC2fIJZmJGUzlUkxnc+QjiewYpCyHWzbxKS98W/gAyEEhIRhQCuMMRqPM5ZNkkmuc25pBecKmK12BfNrqsCLCzASW8GJWVxeMUg6Do4JiVh/B1oZTgpNIjIQwjB6psMAcrH+/4iLOzbHxtJ4LR/HDEnHSyzGanhXIGW1tzYhBLcJgd0+y5SOAUmwQohlwQ4MzCDEBQJM4kaMsakMh8ZTTGVyJC0TxzFJOBYGBnbMxgxCLMvEtAzCMMTf2o7FC8B2A5yUQSJhknVsUrE4NldgEWK1dnDaKijOGvD1i5BwFgl9k2TK5rCZw7Yt7D67s1Gk/z9RRESARtOl8+rcJGANyA/lTDLO/TM5TMvANi3S8ThhdZ3USLv4ZMOHjNlet2SbYMYsAj/EISB0wTNsTBtyTowDozkmR5JM5DLELQvLDIlZMRzbJB4ziVkWcdu8aUHKMAxx/YCW61H3Qpq+T8KycRyLmO1gGucJFyCowTrtBevQXrT+rbMQs1aJJ5KkLIuYY5OJG5i6TCd9RKFJRAaC6/l0VmkatfqrGvjtZBMxjk9midkm+XScammd0alJqrU6mAYNNyBwt047AcQsTMPDsm1SpsNEPsd0PkEmFsO2bGKWSTphk4o7xCyTmG1jGrcuBmoYBjHbwrFMHD+g6Rm4ltE+axSzsDhCEF7EvwKNFpHvx+kQcgstcpk1riQtMok4thEnGXO0vkn6hkKTiAyEzUa0sOXkSP9VA78VwzDIJuMcsy0yjs3KokN2fISSE8f33fb1ycAjxMI0DQwzRsJpF5XMpBySdpxEzCbhWORSDknHxrZMLNN83Wd7DMMgbltYpkELA8exsC0bcybEt0wIz+NfgFbYruF0zQtlyF0pYdkxcg4k4hPEHBt7gL5PMtgUmkRkIFSb0dB0oA+rge9FwrGZHc9weCTLoZkxyiMNqi2f8madADDCkFjMImHb2PEYadsk6TikkxapWAzLNDAN87ZnlfbCNk3MmE0rCDAME4t0u5xA6xBhcJnaxXYtqWulCJpAcRGSzhJJx2Ykk8axdZlO+odCk4gMhNVStN7AdHxwLs3tZJkmuWSc6ZEk+XSClu8RTuXxPA/DaIdFC4NYrH3Jzd7a++1uBKWdTNMkbhiAjxF3GLNSPHgwJCTE5QrBxfaeeddcATLzkBtZYXQpTiJmETNTxB2VIZDep9AkIn0vDENWqjs26x0f6dJo7h3bsrAtSGMThiFB6BCG7WB0LX8Y7P9lSsMwSNg2TXxCbEZzaY4F7YXim/UFGsvRUgTFAJLnW2TsEuPZGEnHaa+LUmiSHqfQJCIDoVTejLQnUtkujaQ7DMPA6nLoiNvX7rizmcylcWcCNptNXHedSim6MPx8FfJX1smnEmSTaRJxh1RMl+mktyk0iUjfC4KAq8tepC+TUvHEbojbFiEh6bjDgbEMjcY41VqDykadF8Pt40rAayuQzy8ykYuTTBg4ZpqYbekynfQshSYR6XtBGLK8Ee1LJ+PdGYyQsG3AI43NzHiWE+40ZfcStTM+ZzuOuwTkLgeMplcZzyZIxxPYloWlzCQ9SqFJRPqeH4YsNKJ9ubjONHVT3LIIw5B8JsF9E3kq1RabjXlKl6KV2y82IHW+wnhqjUwqS9w2STi2LtNJT1JoEpG+F4Sw2tHOg7bo6DLDMNrByYbRTIITB8bZbDapVlb5amn7uApwYQNeurLEVDZFOjaJnUkSc/TjSXqP/lWKSN9rNF0qHe1JE5JxXZ7rNtM0STgQBCGjGYfj03nWqnWq9Rrf7lgVvgScXYDpsWXGRzMkEzEsq108U6SXKDSJSN9rudFF4AfGBrOwZT8yTZNE3CYXxjng5XjooEepcoG1y9H6TZdakDxdZTy5SDoRx7F0mU56j0KTiPS92o4tVKYmFJp6iW2apGNx3DQcHM1y/8FJmt4yqwtwrbpWDbhUg29dWGZ2LMtI3MI2DWK2fkxJ79Cnioj0vVKtFmlP6865nhOzTbJJm/Fsggem8hycSPFwJnrMKlCch2fPXubKRoOm5+MH4U1fT6QbFJpEpO8trke3UJkaG/xq4P0oblmMpuJMj2Y4MT3BzKTBgzuOWQK+daHF6ctLrJRbtHyfMFRwkt6g0CQifa9UjdYbmEjnujQSuRXTNEnGHUbTcQ6Oj/DQwWkOHoapjmOawOUafPPVBS6vrlKt1nF9v1tDFolQaBKRvhaGIaUd+86pGnjvskyTXCLBWDrOfeM5DueS3Ldjx5sScHoRvvHaRS5tNnWZTnqGQpOI9LUgCLiyYwsVVQPvbTHbZCwbZyyf4YHZaQ5MmZzYccwC8NxrHmfOL7BebdLyfQJdppMuU2gSkb4WhCErpWifqoH3vlQsxmQqzoF8lgdnp5g9FL1M5wOLLXj65SXOLa5TrTXwPK1vku7SvZwi0tf8MGTJ3W6nAceyujYe2RvDMMil4kxkXRpenvVKlcZmhaXS9jEl4PwGfP30a4wkE5xIxjBDE1u1m6RLdKZJRPpauGMLlVkgEYt1azjyOlimyWQuRT6d5MHpCWYm4KEdx7Qv08FLlxZZrTRp+YEu00nXKDSJSF9rui6dVZqmRlXYsp/EHZsD+QSjI1keOzTL9I7LdAFwMYCvFlcoXlqiVq3j6jKddIk+WUSkr9Xr0Wrgs1MKTf0ml0gwlY0zkctxcjLHsQnoXJXWAl4twdfmLnB2tULT83Q3nXSF1jSJSF/bWW5gOp3s0kjkjTIMg6mRFJWWz/3uNGubNcrrHnMd5ZlWga9fhsnxecaSSbwgwAsCbAVkuYf0r01E+tpqpRJpT42psGU/si2Lw6MpctkEJw9OMz0D0zuOWQFOnSnzrYsLlGsNWn6gM05yTyk0iUhfWypVI+3RVHaXI6XXpeIxjoylGM1meWJ2nKOj0Lk9nQ+crsHX565ybrVCvd7CVf0muYdueXmuUCg8CnwcWAeKxWLxl7f6/zzwQcAAPlssFj+13wMVEbmZUi26hUpO1cD72ngmxYExDy/wWK3WqZdrvNBxma4GnFqBVgVOFtY5cWAM0zBwLBNDpQhkn93uTNNHgU8Ui8WPAN9fKBSu/YtcAf4a8HeAP7eP4xMR2VUYhmxUW5G+lApb9jXDMDg8liafSXHy6AzHjloc2XFMGfh2E77+yiUuLm1Q9zxcP9AddbLvbrcQfBa4vPV1CRgDVovF4hcKhUIa+BfAz9zuTebm5u5kjLfVaDT2/T162TDPf5jnDpp/rVbj268Gkb7582epry53aUT3zqB/75v1Oisrm+R9n5GbPF4B/mCuxkbpZZ44aDMzOkLCtrFNY+DPOA369/52ujn/24Wmy8Ah4BLtwLQGUCgUDgM/C/x0sVi8vPvT206ePHmHw7y1ubm5fX+PXjbM8x/muYPm/8KLL2IYZdg6wRAHnnziCZLxwd97bhi+94dLFc4sbjJ9eJXY80u8uAmdBSbWgfNL8OB9Y4xMznBwPEvcsbHNwb5UNwzf+1vZ7/mfOnVq18dud3nuF4GfLxQKvwT8FvCrW/2/Qrt0xk8UCoWP341Bioi8Xn4QsNJxReYQ2kJlkMyMZJjOOoymM7z5vhTHdjweAi/58JUXlnjx0iqL6zWaroenS3WyT255pqlYLM4BH+7o+uRW//ft56BERPbCDwKudrSnRlTYcpAYhsH9U3kqXohtzrDRvEL1TJNLHcf4wLObYL9wBcswwJxiKpckjq3F4XLXqbiliPStputG2gemFZoGjW3bPDKd47m6z8OHp2h6l6ifa9+NdE0DeLYE1suXwYCHD00wlU+RdGwc28JUcJK7RJ8uItK3as3oFioHs4kujUT2UzIe5+TBHLlUhrffP8sTB248ZhN4ZgW+9OJlvn1xkfn1GpV6k6bn4wXBjU8QeQN0pklE+tZqOVpuYDyvauCDajST4tiky6tLHu8sTLNydZGXgc5zjRXgxVXwX75KEAYcnxpnejQkn4oRt0xsnXWSO6TQJCJ9azO67RxjGVUDH2SHJkbwg4BXPJ8nDkO2Ak+Xrt88CbRv8X5xFZovLlK7v0Xdm+bASIqJbJxYCLbZvllAa53kjVBoEpG+tV6LtkcSKmw56I5M5nFDuHIR3nloFObW+XIpeswG8HIJ6i+ss1Da4PFjs2y6Y+QTDvmkQywWw7EMLNPUmSd5XRSaRKRvVXaEpmwi1p2ByD1jGAb3jWd5ORcnlh/nux6xCF5a4Sul6HE14HQLWq8FlKuXeeTwJgenxhjNZMgnXdIJh7jdvsPOskws01CAkttSaBKRvhSGIRvRbefIprQQfBjYts2x0RzmaIqLwPufsIm/tMDTK+0Cgte4wBlgbQEWyyUeLNe4L59leizPaDpJKumQsG3icQvHMHFsA9uyts5AgWkMfnVxeX0UmkSkLwVBwEp0HThxR5fnhoVt25yYzmMCZz2f9zxxkMzpK/zxpfZZpk6rwGoNNoot5sdWmR6rMpmNMZFLMZZOk0vFScRi7bpOJsQsC9s0cRwDyzCwTAvbAtswcOz2j02FqeGk0CQifSkIw0hhy/tQNfBhcy04JRyL0/MbvKVwmNHcEn/yUpOLNzn+AnBlDQ6sNZhONsjkyoxnY2QzcZJOnJGkQzYZI26aOPF4+4wTYBhgmTaWBY5pEHcc0nGLdNwhGbOxVBtsaCg0iUhf8oOAckf7gKqBDyXbtjk2NYpjGpxe2OT49AHy6Q2++vI639y88XiP9maql+qQqcPUYot8skUiXSFmg2lCMgZxJ44ds8jaNo5jkYg5xC0Ly25/nY85xOI2I8k42VScXMIhGdOZzkGn0CQifanRjF6bm5lUaBpmhybyZJIJXrlSwg0D3vOmGMcWV/j6GZ8Luzxnc+sPdYjVIQvkgZgFyVQTw6B9Wc5sn22KJSBhQ8yAfC5Hzokzmo4zOpJiPJ1kPJ9mLOlg6YznwFJoEpG+1PS8SPvQiBaBD7t8OsFTx8a5uBbn/GqV0DAZTVe5uFzm1JX21iu71QZvsbX2Cdob2lXa/cmOPwYwaoCZBGe5zHgOEnEYz+eZzmaYrrc4NJJkajRNUuvrBpJCk4j0peVSOdKeHB3p0kiklziOw/3To0xkk5xZcrhs2iSTccZHKyyvNTg93z67tE77Ut3t1Lf+XHM5BGrts1KxTZgAUqkSU/kSBydzrI7kKHgTHBrPkI6rBMagUWgSkb5UrkbvkZrIqhq4bBtJJXjqaJz7xnJcXCtzaTVLMrHBaG6TUrXJZhVKa+0TSleJlirYi60TUawCVg2ma7BUKrMxW6Pmtmi6U9w/k1dwGjAKTSLSlxY3o0WaMnFdDpEowzCYyCWZyCV56ECTpY1Rzq9ucHmlSqlWZTlXpuXBUQ9adahVoeG1SxZs0g5G/h7exwfmgfkaLL/qsbC6RMvzCYGTB8eI2fpROyj0nRSRvrRejm48l1dhS7mFVDzOfVNxjkxkad7vsVFrsV5tcHVtk1K9yUatTrPVxPcDDMPGx8fzfLzQp9b02FiFsg9uCxbdrbVPN3EZKK9DY26Vlu8TM6FwcEI3KQwIhSYR6UuL69HQlNSZJtkD0zRJxmIkYzFm8hkemh2n5Xm4fki96bLZdKk2WzTdgLrn4wcQBi4+4LVCKo0WtVad+ZU1Li/DK+X2XnedysCpTWi9UMKyTDLJBIcncl2YrdxtCk0i0nfCMGRlx0+qRExrR+T1M4x2scq4A5lEjEna/77CMMT1PFpBSKMV4IUBbsul4fq4ARRmp1kqV3lLqcIrF9f54nJ725ZOL7jgvLLGaCJJPhXTNj8DQKFJRPpOEASR0HQIsHX5Q+4SY2vPuXgsRhzIbmWdMAzxfR8PaLoBxydHWNuscnR6nAfmr/KF56u8suO1nq1A+vQVpiYyvOP4AV2m63MKTSLSd/wgiKwpOTKCCgrKvjMMA9u2sWkXuQwTDvl0jPFcmgO5NAfH1/gv37jElyvR531pEWbmXuW+sSyzY7pM188UmkSk77Rcl5WO9uykNlCVe8/Y2sB3ImuTT8VJp2OMpJMkv3qa/7ocPfaPX/E5NHqeH3rbQ8R0Kblv6TyhiPSdWrMVuRX88Fiqa2MRAbAti8NjWR6YyfMX3v0o3zMVfXwN+PzzKxSv7HbfnfQDhSYR6TvlevTOucm8qoFLb5gayXBsKssPfefDvDUdfez5OvxJ8Ry1ZrM7g5M7ptAkIn1nrVyNtEdSOtMkvSOfTnJsOs+H3/8gB3c89l9faPDihcWujEvunEKTiPSd5R1bqIymdSu39JZ8OsEDs+P82HeOR/qvAv/5hVepNho3f6L0NIUmEek7a6Xo5bmRVLxLIxHZ3WgyxlsLx/mhY9H+PzoLz702351ByR1RaBKRvrOyIzQlHFUDl95jWRYT2SQfettjHOrod4HPvXSems429R2FJhHpO8vrQaSt0CS9Km7bHJzM8WPvmYn0/94FmLu0ssuzpFcpNIlIXwnDkKul7fYUKmwpvS0Ts3nzsUO8Y8dNnp994TSu53VnUPKGKDSJSF/xfZ9SuN1+IKvQJL3NsizGMyn+wndFFzf95mtwfmm9S6OSN0KhSUT6iut5XO1oH5ru2lBE9iwZsyjMTPCeiWj/F196jSAIbv4k6TkKTSLSV2rNZqQa+NHJTNfGIrJXhmGQTSb5we+4P9L//z5fY6lU7tKo5PVSaBKRvrJei945N5rNdmkkIq9PMmZx38Qo3zW23bcBPHvu6q7Pkd6i0CQifWWtvBlpj2XSuxwp0lsMw2AkneJD7zwa6f+Pn7tKXVur9AWFJhHpK1fL0Wrg46oGLn2kvbZpiseT230vAq8urHVtTLJ3Ck0i0lc2KtGCgJlErEsjEXn92mub4vw375iN9H/umTnCMNzlWdIrFJpEpK9cXYueaUoldKZJ+kvSsXj40BSd5S4/dRZK1equz5HeoNAkIn1lZTV6e3bMtrs0EpE3xrIsJkfSfN/J7X+7IfDieS0I73UKTSLSN8Iw5GrH3dljgGnqY0z6Tzpm89aTxyN9n376Eq7rdmlEshf6tBGRvuG6Lp0VbQ6i0CT9ybYsjk6M8q6O8gNfKMNSpb77k6Tr9GkjIn2j3mhEqoEfVokm6WOZZIz3PXk40vfNV851aTSyFwpNItI3NmrRReAHxnY5UKQPxG2LB2fyjHb0/X9Pr9JUzaaepdAkIn1jpbKjsKXONEkfM02T6dEc33vCuN73GrpE18sUmkSkbyzVor+Bj6R155z0t1TM5i2FY5G+b7xytkujkdtRaBKRvlGuRENT0nG6NBKRu8M2TY5NjtBZ6vLXvlrSJboepdAkIn3jymol0k7F410aicjdYRgGY5k0f/rh7SKtF4H59cruT5KuUWgSkb6xVvYjbRW2lEGQcCweeyB6F90zZ3SJrhcpNIlI37i6tP31NO3KyiL9zrYsjk/m6Cx1+Z++tqlClz1IoUlE+oLneSx17KBSGFdhSxkcI+kk7388fb39GrBS0V50vUafOCLSF+qNBusd7Qdndz1UpO8kHJsThycifV/XJbqeo9AkIn2hUqvR6Ggfmhjv2lhE7jbLNDkxPcGRjr7f+WIJz/O6Nia5kUKTiPSFy6VypD2ZG+nSSET2Rz6T5AOPpa63XwJqrVb3BiQ3UGgSkb6w0Yguip3MpXc5UqQ/xW2Lk0emIn3PnLnQpdHIzSg0iUhfWK9Ef+POJFTYUgaLbVkcGR8h39H3ma9dJQzDbg1JdlBoEpG+ML+6EWmrsKUMosl8lg92FLr8fBmqqg7eMxSaRKQvrG5sL4h1UGFLGUwJ2+KR2ehddGcuXe3SaGQnhSYR6QuXFra/PooKW8pgsi2LYzOjdP5K8PvfONe18UiUQpOI9DzXdekoBs7xaRW2lME1lc/ygY46ZL8/Dy2VHugJ+tQRkZ63Uamw2dF+/L7UrseK9LtkzOGJB6avtwPg0sJK9wYk1yk0iUjPW6/VqHe0Z0fy3RqKyL6zTZPCgei6ps+//HKXRiOdFJpEpOfNl6N7cE2Oj3ZpJCL7zzAMZsdyvLmjFNnvfAt83+/eoARQaBKRPrBWjt5ynU+r3IAMtnTc4Z2Pbm8VtAhsNlQdvNsUmkSk5y2Xa5F2Jh7r0khE7g3HMnlwKhfp+8bpM10ajVyj0CQiPW9xJRqa4o6qgctgM02To5NjdG6q8plnVgiCoGtjEoUmEekDl1e3v55CNZpkOIxmUrz7IeN6+4sl8BSauuqWJXULhcKjwMeBdaBYLBZ/eav/JPBzwHPFYvHn9n2UIjK0XNdlqbHdfiivGk0yHGKOxeMHZ/mPr1y53nf24nwXRyS3++T5KPCJYrH4EeD7C4XCtchbB/73fR2ZiAhQr9fp3HXukSNdG4rIPWWZJicOjEf6fu/ZV7s0GoHbnGkCZoHLW1+XgDFgtVgsni8UCvft9U3m5ube0OD2qtFo7Pt79LJhnv8wzx2GY/5n569S6Wj769ufKcMw/90M89xheOZfqTd4FHhxq/0b5+DdRzeHYu676eb3/nah6TJwCLhEOzCtvZE3OXny5Bt52p7Nzc3t+3v0smGe/zDPHYZj/ku+xfbvbvAd7zzJySMHgOGY/26Gee4wPPN3fZ/vbb7Ei1/ergheb7V42xDMfTf7/b0/derUro/d7vLcLwI/XygUfgn4LeBXAQqFwl8C/hbwpwuFwk/epXGKiNxgvRqtTTOeTXZpJCL3nm2a3D8ZLeb6/JnmLkfLfrvlmaZisTgHfLij65Nb/Z8CPrWP4xIRAWBhI1oNPK0aTTJEDMPg2NQYR4ELW33/eRn+bhDohogu0N+4iPS0lZJqNMlwyybjfPfj23uqLANN1+3egIaYQpOI9Czf97m0HF5vH0Q1mmT4OJbJI4cmI30vvHZhl6NlPyk0iUjParVaLHacaHrTjGo0yfAxTZPjEyN0Xpj+g2cv73q87B99+ohIz1oplyPlBh45rI16ZTiN5zJ87/Ht9h9ebd9ZJ/eWQpOI9KzFSo1yR/vIzIGujUWkm5Jxh0cOTUf6Liwud2k0w0uhSUR61tVyPdI+NDXWpZGIdJdlmtw/MRLpe/rlYpdGM7wUmkSkZ61uRO+cS8d155wMr6PTYzzS8b/Abz/nE2gD33tKoUlEetbVtWiNpqTKDcgQyyTjvPWR1PX2FaBUqe7+BLnrFJpEpCcFQcCV1e2FrmnAsW+385PI4LJNk8d2rGt65vS5Lo1mOCk0iUhP8jyP+Y3t9pMZlRuQ4WYYBsenRiM/uH//2RVdoruH9AkkIj1pbXOTjszE40e7NhSRnjGZy/D27St0fLUM9ab2ortXFJpEpCddXitHyg2cODTbtbGI9ArHMjmx43+F80vr3RnMEFJoEpGeNL+2GWkfnZ3q0khEeodpmhzJRvv++NlXujOYIaTQJCI9aedGvdmkqoGLABwcH+WtHcHp069Co9Xq3oCGiEKTiPScIAhY2Iyu00jHYrscLTJcErEYTxW2C12WgVWVHrgnFJpEpOd4nsfCunu9PQ5YltW9AYn0EMs0KcyMRvq+9KKqg98LCk0i0nNqjQbza9vtPzWlcgMine6fHmemo/3552r42sB33+lTSER6znypTEdm4pEjujQn0mliJMM7H9ou9vqsC+vV2i2eIXeDQpOI9JwLK2UqHe2Hjx/v2lhEepFlGDxx+ECk77Urq10azfBQaBKRnrO8Hl3UemDH7u4iw840TQrTI5Ef4r/ztbOEYdi1MQ0DhSYR6SlBEHBloxHpS2rPOZEbHBjN856Oreg+vwLler17AxoCCk0i0nMWy9t3zllAzHG6NxiRHpWI2Tx5fOJ62wfOLqg6+H5SaBKRnlKpVrm8vN3+rpzunBO5GdM0eeK+aKX83/+aSg/sJ30SiUhPuVIqU+poP3GkWyMR6X2Hxkd5uOMn+Z9c0SW6/aTQJCI95fxSmY2O9pMPF7o2FpFel4o7fPdT0ergF3WJbt8oNIlIT1nesefcgYl8dwYi0gdM0+Txw5ORvv/6vDbw3S8KTSLSM4Ig4PJG9NJCWovARW7pgekJjna0P/sqVJrNXY+XN06hSUR6Rq3RYHF1e7f2GSCmjXpFbimbSvDuJ1LX20vAhatruz9B3jCFJhHpGYulMldK2+33HOzaUET6hmmavPXYTKTvS3OnuzSawabQJCI94+J6LXLn3JseObDboSLS4aGZSTp/x/iDF33Wq9Vdj5c3RqFJRHrG/OI65Y72g7OTux4rItty6STveyJ5vb0IXFyu7P4EeUMUmkSkJwRBwMVSdBH4RC7bpdGI9BfTNHnbseiZ2c9/+2V83+/SiAaTQpOI9IRqvcnlxe1F4A4Q1yJwkT176MAUhzvaf1iE1U0VurybFJpEpCcsbGxwdXO7/YE8GIbRtfGI9JtsKsEHnty+i24dOD2/0r0BDSCFJhHpCZfWqnRsOce7npre9VgRuZFpmvyp49FbTj/7wlmaqtl01yg0iUjXBUHApcUSjY6+hw5N7Xq8iNzcycMzFDpO0P7RBZhf39z9CfK6KDSJSNd5QcCFtej2KdP5kV2OFpHdOJbF9709f70dAKfOXeraeAaNQpOIdN3aRoWlVfd6ewxVAhd5I0zT5F0PHo70ffrLa2zUars8Q14PhSYR6boLq2UudJSU+dCx7o1FpN8dmBjjuya2268A569udG08g0ShSUS6KggCLiyUWejoe/dbTnRtPCL9zrEsvvfJQ5G+z74yR6vV2uUZslcKTSLSVV4Q8NpKOdJ3fHpil6NFZC/efHSazt3ofvtlOL+is013SqFJRLpqZaPCwtr2LdExIJVIdG9AIgNgbCTLn39r7nq7CTzz2kVVCL9DCk0i0lXnlstcWN9u/8BBFbUUuVOmafLek0cjfb/+tQ2WK6oQficUmkSka7wg4LWFElc6+v7MdzzYtfGIDJJDk+N8sGNp0zzw7PkrBEHQtTH1O4UmEemaRqPFa4ulSN+xidHuDEZkwJimyQefui/S9+lTV1ivNm7+BLkthSYR6Zpzy2ssLGyvsTgMpNPp7g1IZMA8cfwIjznb7WfX4NmL8zrb9AYpNIlIVwRBwLmlMq913AX9w2+Jd29AIgMoZtv82AeixS7/4NRFSjrb9IYoNIlIVzRdn7lL63TeBP2exx/q2nhEBtXbH7yPzspnTy/Cs5d0tumNUGgSka44t7jC/HL0Tp6psbEujUZkcMUdh7/6/tlI369/+SKrupPudVNoEpF7LggCziyWmOuoaflXHlSpAZH98p2P3k/nfanPb8BXihfwPK9rY+pHCk0ics9Vmy4vXVyjozwTH3rnY10bj8igizsOf+v7Dkb6PvWFBVUJf50UmkTkngqCgDMLK1yc364CbgCHJye7NyiRIfDOkyd4W3a7fQ74wsuvUWs2d32ORCk0icg91XR9Xrq4xrMdN+/81DtS3RuQyJAwTZOf+LMPR/r+9alNTp27ou1V9kihSUTuqSurJc5cWSbs6PvAEw/veryI3D0nZmf48UetSN+//5PzLJRrXRpRf1FoEpF7puV5PH95hWc69k157wjkcrndnyQid9WH3/N27utof6sCn3lujs2GajfdjkKTiNwzV1c2eOnsMssdfX/jQye7Nh6RYZRMJPjHP3wi0vevT23yJy+dw3XdLo2qPyg0icg9UW+6fOX8It+4tH2L88PA/QcOdG9QIkPqsaOH+ftvcSJ9/+pzV/nW+Xmtb7oFhSYR2XdBEHD26jIvv7rAUkf/P/nvdZZJpFv+4ru/g/d27I+9AfzL33uN01dWVC18FwpNIrLvNhotvnJmic9c3e57dwaO6yyTSNeYpsnP/Oh3cKyj77QPv/Dpl3htYV3B6SYUmkRkX9WbLl85c4kvP78W6f+HP/LmLo1IRK6Jx+P8m//hLXSccOKVBvyDT32Lb59VKYKdFJpEZN+4vs+3LyzwuW9c4uWO/l94/xjj+Xy3hiUiHXK5HL/+40+S7+i7CPzN3z7Dl+bO0tTi8OsUmkRkX3hBwLdfm+d3v3qGL5a2+z84Ax948k3dGpaI3MTo6Ch/8JF38URHnw987I8u8Sv/5WlWytVuDa2nKDSJyF3XdF2+ceYyn/r8Gf5Lx8rvo8BP/8h3dW1cIrK7WCzGv/nYe/kb0WoE/IeXA/7Mr3ydz3zjW0O/5YpCk4jcNUEQsFKp8nvPneaf/O6rfKm8/dj9wK995F3Ytt218YnI7f31H3gvv/OXHrqh/x99YZV3/9LT/PZXTrE5pOFJn14icseCIGCj1uDpMxf5Pz87z6Udj//IMfjID74by7Ju+nwR6S0HZ2f55sdm+caLL/K3/2gp8tgvPL3BLzz9NGPAT717lHc8fpJUItGdgd5jtwxNhULhUeDjwDpQLBaLv7zV/xeB7wZiwL8tFotP7/M4RaTHuK7LykaF5y4s8O8+t8C5XY77nR99mIMzM/d0bCJyd7zt0Uf55qOwsLDAX/4PL9N5D+wa8FNfWIcvfOV631PAX35fnicffpjEAAap251p+ijwiWKxeKlQKPxhoVD4P4rFYgj8tWKx+IFCoZAEPgV0NTR9+Pevwu9fvf2Bg2yY5z/Mc4eenP99wL/+q08wPj7e7aGIyF0wMzPDf/5Y+5efjY0NPvrJU3z7JsedAk79cQn++Cs3efTOffNj792X192r24WmWeDy1tclYAxYBQKAYrFYLxQK6du9ydzc3B0MUUT6wT+8H06e3C5WubS0xNLS0i2ececajcbQfr4M89xhuOffC3P/H7//xsK0n/nMVX7Nu8nBd9Hc3FxX53+70HQZOARcoh2YItXptgLTbe9DPHlyf7dK+L/vwXv0srm5uaGd/zDPHTT/YZ7/MM8dhnv+vTr3kydP8vfvwfvs9/xPnTq162O3C02/CPx8oVAoAb8F/Crw48CvFgqFX6G9pumf351hioiIiPSuW4amYrE4B3y4o+uTW/2/CfzmPo5LREREpKeoTpOIiIjIHig0iYiIiOyBQpOIiIjIHig0iYiIiOyBQpOIiIjIHig0iYiIiOyBQpOIiIjIHig0iYiIiOyBQpOIiIjIHig0iYiIiOyBQpOIiIjIHhhhGO7rG5w6dWp/30BERETkLnrqqaeMm/Xve2gSERERGQS6PCciIiKyBwpNIiIiInug0CQiIiKyBwpNIiIiIntgd3sAr0ehUHgU+DiwDhSBw7TnMA38JPC3gc8Wi8Uvd22Q++gm8z8GJIFx4GeA/5YBnf9N5r4BvAnIAv8z8FcY0LnDDfM/DTwKlIFR4B8Cf5cBnX+hUBgB/gHwlmKx+IFCofCzwAgwA/ws8OcZ0LnDTef/JeDU1sOfBH6Y4Zr/zwA+7c+/f85gf+49BPwTYAlwgS8APw38ZLFY/HKhUPinDO7ce/Lnfb+dafoo8IlisfgR4IeAqWKx+DHg/6L9QxPgLxQKhf+lUCj8qy6NcT91zv/7gd8tFot/B/ht4Lu2jhnU+XfO/UPAf0f7f6YSsLZ1zKDOHaLz/yAwUSwWfwr4j8CPbh0zqPN3aAfja7cAf65YLP494N8B79nqG9S5w43zH6UdmE1gfqtvmOb/RLFY/GfAp4H3bfUN6vwN4Ce2/r9/DHgJ+KMdxwzq3Hvy532/haZZ4HJHu7b13yu0UyjAH279xT56Lwd2j3TOvwS8XCgU/hHw92h/gMDgzr9z7nHgwWKx+AvAZ4C/vtU/qHOHG7/3LxYKhZ8Dvpv2b14woPMvFosrxWKx3NH+fKFQOE77DMu/3+oeyLnDjfMHfrBYLP5j4Hdp/2CB4Zr/S4VC4ZPA36f9dwADOv9isThXLBYXC4XCTwL/T7FYPHuTwwZy7vToz/t+C02XgUNbX4dAauvro8DFra+r93pQ91Dn/CdoB4efpX2q8ie3+gd1/p1zb7H9G/Y62/8OBnXuEJ3/GO3T0j8NvAK8utU/yPO/rlAovA/4O8DfLBaLG1vdwzL3FHBgq1mifXkehmf+o8ChYrH4N2j/svgTWw8N5PwLhUKsUCj8MvD1YrH4H3Y5bCDnTo/+vO+rNU3ALwI/XygUSsCvA4cLhcK/ACZp/8b1d7s4tnuhc/6/CfxYoVD4Idr/iP5Xtk9VD6LOuf8WkN76MEkBn2D7bNOg2jn/P1coFH4EyAB/k/aaj4FUKBTeQfv0/IlCofAvgR8A/hPwc4VC4avdHNu90Dl/2mu4soVC4c/SDk//E9uXKgbSjvn/NNDcWsszC/wa7bOtg+onaK/d+oFCofADQAX4HqBQKBQmujiue6Enf96rIriIiIjIHvTb5TkRERGRrlBoEhEREdkDhSYRERGRPVBoEhEREdkDhSYRERGRPVBoEhEREdkDhSYRERGRPVBoEhEREdmD/x91gNMtGzAw6QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "lengths =(mover.get_lengthscale_samples(X=Zin))\n",
    "amps = (mover.get_amplitude_samples(X=Zin))\n",
    "#  plot the sample for checking\n",
    "plt.figure(figsize=(10,6))\n",
    "Z_time=np.array([np.datetime64('2019') + np.timedelta64(int(k*60*60), 's') for k in Zin])\n",
    "\n",
    "for i in range(0,lengths.shape[0]):\n",
    "    plt.plot(Z_time[np.argsort(Z_time)],lengths[i,np.argsort(Z_time)],c='C1',alpha=0.02,linewidth=1.0)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis_date()\n",
    "ax.xaxis.set_major_formatter(myFmt)\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "for i in range(0,amps.shape[0]):\n",
    "    plt.plot(Z_time[np.argsort(Z_time)],amps[i,np.argsort(Z_time)],c='C1', alpha=0.02,linewidth=1.0)\n",
    "ax = plt.gca()\n",
    "ax.xaxis_date()\n",
    "ax.xaxis.set_major_formatter(myFmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz=10\n",
    "ls_function = np.zeros((mover.num_samples,np.shape(mover.Z_.numpy())[0],1))\n",
    "\n",
    "for i in range(0,mover.num_samples,batch_sz):\n",
    "\n",
    "    ls_latents_sample = mover.samples_[mover.l_start][i:i+batch_sz]\n",
    "    ls_params = []\n",
    "    for j in range(len(mover.ltransforms)):\n",
    "        ls_params.append(mover.samples_[mover.l_start+1+j][i:i+batch_sz,0])\n",
    "\n",
    "    ls_function[i:i+batch_sz] = mover.get_lengthscale_batch(ls_latents_sample, ls_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kernel_batches = mover.lkernel(*[tf.cast(t(p),tf.float64) for t,p in zip(mover.ltransforms, ls_params)])\n",
    "K_batch = kernel_batches.matrix(mover.Z_,mover.Z_)\n",
    "L_batch = tf.linalg.cholesky(K_batch + tf.eye(tf.shape(input=mover.Z_)[0], dtype=tf.float64) * mover.jitter_level)\n",
    "f_batch =  tf.matmul(tf.cast(L_batch,tf.float64), tf.expand_dims(tf.cast(ls_latents_sample,tf.float64),-1))\n",
    "# if X is not None:\n",
    "#     f_batch = tf.expand_dims(tfd.GaussianProcessRegressionModel(kernel = kernel_batches,\n",
    "#                                                                 mean_fn = lambda _: tf.reduce_mean(f_batch),\n",
    "#                                                                 index_points = X,  \n",
    "#                                                                 observations = f_batch[...,0], \n",
    "#                                                                 observation_index_points=mover.Z_).mean(),-1)\n",
    "\n",
    "f_batch = tf.math.exp(f_batch)# + tf.expand_dims(tf.expand_dims(tf.cast(ls_mean_sample,tf.float64),-1),-1))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.matmul(tf.squeeze(tf.cast(L_batch,tf.float64)), tf.expand_dims(tf.cast(ls_latents_sample,tf.float64),-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.matmul(tf.cast(L_batch,tf.float64), tf.expand_dims(tf.cast(ls_latents_sample,tf.float64),-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ess=tfp.mcmc.effective_sample_size(samples)\n",
    "plt.plot(mover_hmc.kernel_params[0].numpy(),ess[0],'.')\n",
    "plt.ylim(0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[20.674095]\n",
      " [19.737753]\n",
      " [19.273901]\n",
      " [20.348425]\n",
      " [24.591201]\n",
      " [31.988383]\n",
      " [34.753674]\n",
      " [31.313986]\n",
      " [26.400472]\n",
      " [20.811858]\n",
      " [16.201991]\n",
      " [13.5125  ]\n",
      " [10.957685]\n",
      " [ 5.781815]\n",
      " [15.712603]\n",
      " [12.199116]\n",
      " [ 6.833402]\n",
      " [19.624745]\n",
      " [26.800699]\n",
      " [10.160473]\n",
      " [17.643842]\n",
      " [34.628986]\n",
      " [ 7.568584]\n",
      " [14.789849]\n",
      " [20.183788]], shape=(25, 1), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[ 5.342908]\n",
      " [ 7.427637]\n",
      " [ 6.530282]\n",
      " [ 4.157907]\n",
      " [ 3.679837]\n",
      " [ 3.666985]\n",
      " [ 3.748772]\n",
      " [ 3.814841]\n",
      " [ 3.888242]\n",
      " [ 4.007382]\n",
      " [ 4.19593 ]\n",
      " [ 4.403672]\n",
      " [ 4.774092]\n",
      " [19.172334]\n",
      " [ 5.494397]\n",
      " [27.833945]\n",
      " [14.200336]\n",
      " [20.588473]\n",
      " [24.180489]\n",
      " [16.91506 ]\n",
      " [78.580138]\n",
      " [20.088612]\n",
      " [42.863366]\n",
      " [10.369039]\n",
      " [ 7.606518]], shape=(25, 1), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lengths =(mover.get_lengthscale_samples())\n",
    "amps = (mover.get_amplitude_samples())\n",
    "\n",
    "print(tfp.mcmc.effective_sample_size(lengths))\n",
    "print(tfp.mcmc.effective_sample_size(amps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compare full covar to this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lengths =(mover_hmc.get_lengthscale_samples())\n",
    "amps = (mover_hmc.get_amplitude_samples())\n",
    "\n",
    "print(tfp.mcmc.effective_sample_size(lengths))\n",
    "print(tfp.mcmc.effective_sample_size(amps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = [np.std(s.numpy()[:,:],axis=0) for s in samples]\n",
    "#bb = [np.std(s.numpy()[:,:],axis=0) for s in samples]\n",
    "\n",
    "# opt_step=[]\n",
    "# for a in aa:\n",
    "#     opt_step.append(1e-3*a)\n",
    "# opt_step\n",
    "#plt.plot(aa[1])\n",
    "plt.plot(bb[0])#/np.max(bb[1]))\n",
    "plt.plot(aa[0])#/np.max(bb[1]))\n",
    "\n",
    "plt.plot(opt_step_size[0]/np.max(opt_step_size[0]),'.')\n",
    "#plt.ylim(0,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples=600\n",
    "burn=0#250\n",
    "mover_hmc.num_samples = num_samples\n",
    "\n",
    "#v=0.15\n",
    "#s=1\n",
    "\n",
    "def volatility_fn(*x):\n",
    "  # Stack the input tensors together\n",
    "  #return [1. / (0.5 + 0.1 * tf.math.abs(y)) for y in x]\n",
    "    #return [1 for vv in opt_step_size]\n",
    "    return [(vv) for vv in bb]\n",
    "\n",
    "\n",
    "ss=np.float64(5e-3)\n",
    "step_size = [ss for a in opt_step_size]\n",
    "#inner_kernel = tfp.mcmc.HamiltonianMonteCarlo(target_log_prob_fn=mover_hmc.log_posterior, step_size=steps, num_leapfrog_steps=10)#max_tree_depth=4)\n",
    "inner_kernel = tfp.mcmc.MetropolisAdjustedLangevinAlgorithm(target_log_prob_fn=mover_hmc.log_posterior,step_size=step_size,volatility_fn=volatility_fn)\n",
    "#)#, step_size=steps)#max_tree_depth=4)\n",
    "kernel = tfp.mcmc.DualAveragingStepSizeAdaptation(inner_kernel, num_adaptation_steps=int(burn * 0.8))\n",
    "start = time.time()\n",
    "\n",
    "samples, kernel_results = tfp.mcmc.sample_chain(num_results=num_samples, num_burnin_steps=burn, num_steps_between_results=100, current_state=mover_hmc.kernel_params, kernel=inner_kernel)\n",
    "end = time.time()\n",
    "\n",
    "print(end - start)\n",
    "mover_hmc.samples_ = samples\n",
    "print(np.sum(kernel_results.is_accepted.numpy()/num_samples))\n",
    "tfp.mcmc.effective_sample_size(samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(samples[0][:,])\n",
    "plt.show()\n",
    "plt.plot(samples[0][:,3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_history[800:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = mover_hmc.get_lengthscale()\n",
    "plt.plot(Z,lengths,'o',c='b')\n",
    "Zin = np.linspace(0,24,num=500,endpoint=False).astype(np.float64)[:,None]\n",
    "\n",
    "lengths = mover_hmc.get_lengthscale(X=Zin)\n",
    "plt.plot(Zin,lengths)\n",
    "plt.show()\n",
    "\n",
    "amps = mover_hmc.get_amplitude()\n",
    "plt.plot(Z,amps,'o',c='b')\n",
    "Zin = np.linspace(0,24,num=500,endpoint=False).astype(np.float64)[:,None]\n",
    "amps = mover_hmc.get_amplitude(X=Zin)\n",
    "plt.plot(Zin,amps)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_step = []\n",
    "ss=1e-6\n",
    "for var in optimizer.variables():\n",
    "    #print(var)\n",
    "    if '/m:' in var.name:\n",
    "        opt_step.append(ss*(np.sqrt(np.abs((var.numpy()))))**-1)\n",
    "        \n",
    "        \n",
    "plt.plot(opt_step[2][0:],'.')\n",
    "#plt.show()\n",
    "plt.plot(opt_step[6][0:],'.')\n",
    "plt.show()\n",
    "#plt.ylim(-0.5,1)\n",
    "#plt.show()\n",
    "\n",
    "for o in opt_step:\n",
    "    print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp_params = [kernel_params[i] for i in range(mover_hmc.a_start+2,mover_hmc.m_start)]\n",
    "\n",
    "\n",
    "K_amp = mover_hmc.akernel(*[t(p) for t,p in zip(mover_hmc.atransforms, amp_params)])\n",
    "L_amp = tf.linalg.cholesky(K_amp.matrix(mover_hmc.Z_,mover_hmc.Z_) + tf.eye(tf.shape(input=mover_hmc.Z_)[0], dtype=tf.float64) * mover_hmc.jitter_level)\n",
    "amp_dist = tfd.MultivariateNormalTriL(scale_tril=L_amp)\n",
    "\n",
    "\n",
    "ls_params = [kernel_params[i] for i in range(mover_hmc.l_start+2,mover_hmc.a_start)]\n",
    "\n",
    "K_ls = mover_hmc.lkernel(*[t(p) for t,p in zip(mover_hmc.ltransforms, ls_params)])\n",
    "L_ls = tf.linalg.cholesky(K_ls.matrix(mover_hmc.Z_,mover_hmc.Z_) + tf.eye(tf.shape(input=mover_hmc.Z_)[0], dtype=tf.float64) * mover_hmc.jitter_level)\n",
    "\n",
    "ls_dist = tfd.MultivariateNormalTriL(scale_tril=L_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(opt_amp_amp)\n",
    "print(opt_ls_amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss=1e-2\n",
    "ss_l = ss/opt_ls_amp\n",
    "ss_amp = ss/opt_amp_amp\n",
    "\n",
    "def _fn(state_parts, seed):\n",
    "    \n",
    "    next_state_parts = []\n",
    "    for j, param in enumerate(state_parts):\n",
    "        if j==1:\n",
    "            next_state_parts.append(state_parts[j] + 2*ss_l*ls_dist.sample())# + 1e-1*gradients[j])\n",
    "        elif j==3:\n",
    "            next_state_parts.append(state_parts[j] + ss_amp*amp_dist.sample())\n",
    "        else:\n",
    "            next_state_parts.append(state_parts[j])\n",
    "\n",
    "    return next_state_parts\n",
    "\n",
    "\n",
    "num_samples=10#00#500\n",
    "burn=0\n",
    "mover_hmc.num_samples = num_samples\n",
    "#skip100,nsamp1000 - gives min ess of 8 looks like with burn in would be ok\n",
    "\n",
    "kernel = tfp.mcmc.RandomWalkMetropolis(target_log_prob_fn=mover_hmc.log_posterior, new_state_fn=_fn)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "samples, kernel_results = tfp.mcmc.sample_chain(num_results=num_samples, num_burnin_steps=burn, num_steps_between_results=1, current_state=mover_hmc.kernel_params, kernel=kernel)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "mover_hmc.samples_ = samples\n",
    "print(np.sum(kernel_results.is_accepted.numpy()/num_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10000*5619/60/60/2000\n",
    "print((end - start)/60/60)\n",
    "print(np.sum(kernel_results.is_accepted.numpy()/num_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = mover_hmc.get_lengthscale_samples(X=Zin)\n",
    "amps = mover_hmc.get_amplitude_samples(X=Zin)\n",
    "#  plot the sample for checking\n",
    "plt.figure(figsize=(10,6))\n",
    "Z_time=np.array([np.datetime64('2019') + np.timedelta64(int(k*60*60), 's') for k in Zin])\n",
    "\n",
    "for i in range(800,lengths.shape[0]):\n",
    "    plt.plot(Z_time[np.argsort(Z_time)],lengths[i,np.argsort(Z_time)],c='C1',alpha=0.02,linewidth=1.0)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis_date()\n",
    "ax.xaxis.set_major_formatter(myFmt)\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "for i in range(800,amps.shape[0]):\n",
    "    plt.plot(Z_time[np.argsort(Z_time)],amps[i,np.argsort(Z_time)],c='C1', alpha=0.02,linewidth=1.0)\n",
    "ax = plt.gca()\n",
    "ax.xaxis_date()\n",
    "ax.xaxis.set_major_formatter(myFmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfp.mcmc.effective_sample_size(samples[1][800:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(samples[1][:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = mover_hmc.get_lengthscale_samples()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples=1000#000#00#00#0#500\n",
    "burn=1#1000#000#5#0\n",
    "mover_hmc.num_samples = num_samples\n",
    "steps = []\n",
    "\n",
    "#ss = opt_step#np.float64(1e-5)\n",
    "def volatility_fn(*x):\n",
    "  # Stack the input tensors together\n",
    "  #return [1. / (0.5 + 0.1 * tf.math.abs(y)) for y in x]\n",
    "    \n",
    "    vol = []\n",
    "    for i in range(len(x)):\n",
    "        if i==1:\n",
    "            vol.append(1e-2*tf.eye(tf.shape(x[i])[0],dtype=tf.float64))\n",
    "        else:\n",
    "            vol.append(1e-2)\n",
    "    return vol\n",
    "\n",
    "\n",
    "vol = volatility_fn(*mover_hmc.kernel_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ss=np.float64(1e-2)\n",
    "steps=[]\n",
    "for i in range(len(mover_hmc.kernel_params)):\n",
    "    if i==1:\n",
    "        steps.append(ss*tf.ones((tf.shape(mover_hmc.kernel_params[i])[0],1),dtype=tf.float64))\n",
    "    else:\n",
    "        steps.append(ss)\n",
    "#inner_kernel = tfp.mcmc.HamiltonianMonteCarlo(target_log_prob_fn=mover_hmc.log_posterior, step_size=steps, num_leapfrog_steps=10)#max_tree_depth=4)\n",
    "inner_kernel = tfp.mcmc.MetropolisAdjustedLangevinAlgorithm(target_log_prob_fn=mover_hmc.log_posterior,step_size=steps,volatility_fn=volatility_fn)\n",
    "#)#, step_size=steps)#max_tree_depth=4)\n",
    "kernel = tfp.mcmc.DualAveragingStepSizeAdaptation(inner_kernel, num_adaptation_steps=int(burn * 0.8))\n",
    "start = time.time()\n",
    "\n",
    "samples, kernel_results = tfp.mcmc.sample_chain(num_results=num_samples, num_burnin_steps=burn, num_steps_between_results=0, current_state=mover_hmc.kernel_params, kernel=inner_kernel)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "mover_hmc.samples_ = samples\n",
    "print(np.sum(kernel_results.is_accepted.numpy()/num_samples))\n",
    "tfp.mcmc.effective_sample_size(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss=np.float64(1e-2)\n",
    "steps=[]\n",
    "for i in range(len(mover_hmc.kernel_params)):\n",
    "    if i==1:\n",
    "        steps.append(ss*tf.ones((tf.shape(mover_hmc.kernel_params[i])[0],1),dtype=tf.float64))\n",
    "    else:\n",
    "        steps.append(ss)\n",
    "\n",
    "tf.matmul(vol[1],steps[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample from the posterior\n",
    "start = time.time()\n",
    "num_samples=5000\n",
    "burn_in=2000\n",
    "kr = mover.hmc_sample(num_samples=num_samples, skip=0, burn_in=burn_in, num_leapfrog_steps=10, init_step=opt_step)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "print(np.sum(kr.inner_results.is_accepted.numpy()/num_samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7000*1121/60/60/200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lengths = mover_hmc.samples_[1]\n",
    "\n",
    "for i in range(0,lengths.shape[0]):\n",
    "    plt.plot(Z,lengths[i,:],c='C1',alpha=0.02,linewidth=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lengths = mover.get_lengthscale_samples(X=Zin)\n",
    "amps = mover.get_amplitude_samples(X=Zin)\n",
    "#  plot the sample for checking\n",
    "plt.figure(figsize=(10,6))\n",
    "Z_time=np.array([np.datetime64('2019') + np.timedelta64(int(k*60*60), 's') for k in Zin])\n",
    "\n",
    "for i in range(0,lengths.shape[0]):\n",
    "    plt.plot(Z_time[np.argsort(Z_time)],lengths[i,np.argsort(Z_time)],c='C1',alpha=0.02,linewidth=1.0)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis_date()\n",
    "ax.xaxis.set_major_formatter(myFmt)\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "for i in range(0,amps.shape[0]):\n",
    "    plt.plot(Z_time[np.argsort(Z_time)],amps[i,np.argsort(Z_time)],c='C1', alpha=0.02,linewidth=1.0)\n",
    "ax = plt.gca()\n",
    "ax.xaxis_date()\n",
    "ax.xaxis.set_major_formatter(myFmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(mover.Z_.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = mover.get_lengthscale_samples()\n",
    "tfp.mcmc.effective_sample_size(lengths)#[1].numpy()[39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "step_size = []\n",
    "for s in mover.samples_:\n",
    "    \n",
    "    step_size.append(np.std(s,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in step_size: print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample from the posterior\n",
    "start = time.time()\n",
    "num_samples=1000\n",
    "burn_in=600\n",
    "kr = mover.hmc_sample(num_samples=num_samples, skip=0, burn_in=burn_in, num_leapfrog_steps=10, init_step=step_size)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "print(np.sum(kr.inner_results.is_accepted.numpy()/num_samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lengths = mover.get_lengthscale_samples()\n",
    "amps = mover.get_amplitude_samples()\n",
    "#  plot the sample for checking\n",
    "plt.figure(figsize=(10,6))\n",
    "Z_time=np.array([np.datetime64('2019') + np.timedelta64(int(k*60*60), 's') for k in Z])\n",
    "\n",
    "for i in range(0,lengths.shape[0]):\n",
    "    plt.plot(Z_time[np.argsort(Z_time)],lengths[i,np.argsort(Z_time)],c='C1',alpha=0.902,linewidth=1.0)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis_date()\n",
    "ax.xaxis.set_major_formatter(myFmt)\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "for i in range(0,amps.shape[0]):\n",
    "    plt.plot(Z_time[np.argsort(Z_time)],amps[i,np.argsort(Z_time)],c='C1', alpha=0.902,linewidth=1.0)\n",
    "ax = plt.gca()\n",
    "ax.xaxis_date()\n",
    "ax.xaxis.set_major_formatter(myFmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa=tfp.mcmc.effective_sample_size(mover.samples_)#[1].numpy()[39]\n",
    "\n",
    "plt.plot(aa[1],step_size[1],'.')\n",
    "tfp.mcmc.effective_sample_size(mover.samples_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mover.samples_[2][:,].numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kr.new_step_size[1][0,39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "opt_step = []\n",
    "for var in optimizer.variables():\n",
    "    if '/v:' in var.name:\n",
    "        opt_step.append((np.sqrt((var.numpy())))**-1)\n",
    "        \n",
    "        \n",
    "plt.plot(opt_step[1][0:],'.')\n",
    "#plt.show()\n",
    "plt.plot(opt_step[4][0:],'.')\n",
    "plt.show()\n",
    "#plt.ylim(-0.5,1)\n",
    "#plt.show()\n",
    "\n",
    "for o in opt_step:\n",
    "    print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_history[200:])\n",
    "plt.show()\n",
    "loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1600*942/40/60/60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(mover.kernel_params[mover.l_start].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Z,(mover.kernel_params[2]).numpy(),'-o')\n",
    "#plt.ylim(0,0.5)\n",
    "plt.show()\n",
    "plt.plot(Z,(mover.kernel_params[6]).numpy(),'-o')\n",
    "plt.show()\n",
    "#6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "opt_step = []\n",
    "for var in optimizer.variables():\n",
    "    if '/v:' in var.name:\n",
    "        opt_step.append((np.sqrt((var.numpy()))+1e-16)**-1)\n",
    "        \n",
    "        \n",
    "plt.plot(opt_step[3][0:25],'.')\n",
    "#plt.plot(opt_step[6][0:25],'.')\n",
    "#plt.ylim(-0.5,1)\n",
    "#plt.show()\n",
    "\n",
    "for o in opt_step:\n",
    "    print(o.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(opt_step)):\n",
    "    o=opt_step[i]\n",
    "    if len(o.shape):\n",
    "        o[o>1]=1\n",
    "    opt_step[i]=o#opt_step[i]*0+1e-2\n",
    "    print(opt_step[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, param in enumerate(mover.kernel_params):\n",
    "    print(j,(param.numpy()),param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.math.exp(-1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with open('opt_step.npy', 'wb') as fp:\n",
    "#     pickle.dump(opt_step, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "# with open ('opt_step.npy', 'rb') as fp:\n",
    "#     opt_step = pickle.load(fp)\n",
    "#mover.log_posterior(*mover.kernel_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_ls_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mover.log_posterior(*mover.kernel_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mover_hmc.kernel_params.log_posterior(*mover_hmc.kernel_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lengths = mover_hmc.get_lengthscale()\n",
    "# plt.plot(Z,lengths,'o',c='b')\n",
    "# Zin = np.linspace(0,24,num=500,endpoint=False).astype(np.float64)[:,None]\n",
    "\n",
    "# lengths = mover_hmc.get_lengthscale(X=Zin)\n",
    "# plt.plot(Zin,lengths)\n",
    "# plt.show()\n",
    "\n",
    "amps = mover_hmc.get_amplitude()\n",
    "plt.plot(Z,amps,'o',c='b')\n",
    "Zin = np.linspace(0,24,num=500,endpoint=False).astype(np.float64)[:,None]\n",
    "amps = mover_hmc.get_amplitude(X=Zin)\n",
    "plt.plot(Zin,amps)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples=2000#0#500\n",
    "burn=0#5#0\n",
    "mover_hmc.num_samples = num_samples\n",
    "steps = []\n",
    "\n",
    "ss = np.float64(1e-5)\n",
    "def volatility_fn(*x):\n",
    "  # Stack the input tensors together\n",
    "  #return [1. / (0.5 + 0.1 * tf.math.abs(y)) for y in x]\n",
    "  return [1. for y in x]\n",
    "\n",
    "for j, param in enumerate(mover_hmc.kernel_params):\n",
    "    if j==1:\n",
    "        steps.append(ss)\n",
    "    elif j==3:\n",
    "        steps.append(ss)\n",
    "    else:\n",
    "        steps.append(ss)\n",
    "#inner_kernel = tfp.mcmc.HamiltonianMonteCarlo(target_log_prob_fn=mover_hmc.log_posterior, step_size=steps, num_leapfrog_steps=10)#max_tree_depth=4)\n",
    "inner_kernel = tfp.mcmc.MetropolisAdjustedLangevinAlgorithm(target_log_prob_fn=mover_hmc.log_posterior,step_size=ss,volatility_fn=volatility_fn)\n",
    "#)#, step_size=steps)#max_tree_depth=4)\n",
    "kernel = tfp.mcmc.DualAveragingStepSizeAdaptation(inner_kernel, num_adaptation_steps=int(burn * 0.8))\n",
    "start = time.time()\n",
    "\n",
    "samples, kernel_results = tfp.mcmc.sample_chain(num_results=num_samples, num_burnin_steps=burn, num_steps_between_results=0, current_state=mover_hmc.kernel_params, kernel=inner_kernel)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "mover_hmc.samples_ = samples\n",
    "print(np.sum(kernel_results.is_accepted.numpy()/num_samples))\n",
    "tfp.mcmc.effective_sample_size(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfp.mcmc.effective_sample_size(samples)[1].numpy()[39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = mover_hmc.get_lengthscale_samples()\n",
    "amps = mover_hmc.get_amplitude_samples()\n",
    "\n",
    "aa=tfp.mcmc.effective_sample_size(lengths).numpy()\n",
    "plt.plot(Z,aa,'.')\n",
    "aa=tfp.mcmc.effective_sample_size(amps).numpy()\n",
    "plt.plot(Z,aa,'.')\n",
    "\n",
    "plt.show()\n",
    "plt.plot(Z,lengths[0,...],'.')\n",
    "\n",
    "plt.plot(Z,amps[0,...],'.')\n",
    "\n",
    "plt.show()\n",
    "plt.plot(Z,mover_hmc.samples_[1][0,...],'.')\n",
    "plt.show()\n",
    "\n",
    "aa=tfp.mcmc.effective_sample_size(lengths).numpy()\n",
    "plt.plot(Z,aa,'.')\n",
    "#plt.plot(Z,amps[0,...],'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cauchy_new_state_fn(scale, dtype):\n",
    "  cauchy = tfd.Normal(loc=np.float64(0), scale=np.float64(scale))\n",
    "  def _fn(state_parts, seed):\n",
    "    next_state_parts = []\n",
    "    part_seeds = tfp.random.split_seed(\n",
    "        seed, n=len(state_parts), salt='rwmcauchy')\n",
    "    for sp, ps in zip(state_parts, part_seeds):\n",
    "      next_state_parts.append(sp + cauchy.sample(\n",
    "        sample_shape=sp.shape, seed=ps))\n",
    "    return next_state_parts\n",
    "  return _fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfp.mcmc.effective_sample_size(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = tf.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-3,\n",
    "    decay_steps=10,\n",
    "    decay_rate=0.99,\n",
    "    staircase=True)\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=1e-3)#,beta_2=0.99)\n",
    "train_steps = 500#00#00\n",
    "pbar = tqdm(range(train_steps))\n",
    "loss_history = np.zeros((train_steps))\n",
    "for i in pbar:\n",
    "    with tf.GradientTape() as t:\n",
    "        loss = -mover_hmc.log_posterior(*mover_hmc.kernel_params)\n",
    "    loss_history[i] = loss.numpy()#mover_hmc.kernel_params[1].numpy()[39]\n",
    "    pbar.set_description(\"Loss %f\" % loss_history[i])\n",
    "\n",
    "    gradients = t.gradient(loss, mover_hmc.kernel_params)\n",
    "    optimizer.apply_gradients(zip(gradients, mover_hmc.kernel_params))\n",
    "    #print(gradients)\n",
    "#n=3.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_history[50:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "\n",
    "@tf.function\n",
    "def test_():\n",
    "    def target_fn(*input):\n",
    "        return -mover_hmc.log_posterior(*input)\n",
    "    fn_val, grads = tfp.math.value_and_gradient(target_fn, mover_hmc.kernel_params)\n",
    "\n",
    "# # We can either pass the `sample_shape` of the `state` or not, which impacts\n",
    "# # computational speed of `diag_jacobian`\n",
    "    _, diag_jacobian_shape_passed = tfp.math.diag_jacobian(\n",
    "       xs=mover_hmc.kernel_params, ys=grads, sample_shape=tf.shape(fn_val))\n",
    "# _, diag_jacobian_shape_none = diag_jacobian(\n",
    "#   xs=state, ys=grads)\n",
    "\n",
    "# diag_jacobian_shape_passed_ = sess.run(diag_jacobian_shape_passed)\n",
    "# diag_jacobian_shape_none_ = sess.run(diag_jacobian_shape_none)\n",
    "\n",
    "# print('hessian computed through `diag_jacobian`, sample_shape passed: ',\n",
    "#   np.concatenate(diag_jacobian_shape_passed_, -1))\n",
    "# print('hessian computed through `diag_jacobian`, sample_shape skipped',\n",
    "#   np.concatenate(diag_jacobian_shape_none_, -1))\n",
    "    return diag_jacobian_shape_passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.variables()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as t2:\n",
    "    with tf.GradientTape(persistent=True) as t:\n",
    "        loss = -mover_hmc.log_posterior(*mover_hmc.kernel_params)\n",
    "    #aa = tf.hessians(loss,mover_hmc.kernel_params)\n",
    "    gradients = t.gradient(loss, mover_hmc.kernel_params)\n",
    "\n",
    "#gradients2 = t2.gradient(gradients,mover_hmc.kernel_params)\n",
    "gradients\n",
    "    #gradients = t.gradient(loss, mover_hmc.kernel_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calc_hessian_diag(f, x):\n",
    "    \"\"\"\n",
    "    Calculates the diagonal entries of the Hessian of the function f\n",
    "    (which maps rank-1 tensors to scalars) at coordinates x (rank-1\n",
    "    tensors).\n",
    "    \n",
    "    Let k be the number of points in x, and n be the dimensionality of\n",
    "    each point. For each point k, the function returns\n",
    "\n",
    "      (d^2f/dx_1^2, d^2f/dx_2^2, ..., d^2f/dx_n^2) .\n",
    "\n",
    "    Inputs:\n",
    "      f (function): Takes a shape-(k,n) tensor and outputs a\n",
    "          shape-(k,) tensor.\n",
    "      x (tf.Tensor): The points at which to evaluate the Laplacian\n",
    "          of f. Shape = (k,n).\n",
    "    \n",
    "    Outputs:\n",
    "      A tensor containing the diagonal entries of the Hessian of f at\n",
    "      points x. Shape = (k,n).\n",
    "    \"\"\"\n",
    "    # Use the unstacking and re-stacking trick, which comes\n",
    "    # from https://github.com/xuzhiqin1990/laplacian/\n",
    "    with tf.GradientTape(persistent=True) as g1:\n",
    "        # Turn x into a list of n tensors of shape (k,)\n",
    "        x_unstacked = tf.unstack(x, axis=0)\n",
    "        g1.watch(x_unstacked)\n",
    "\n",
    "        with tf.GradientTape() as g2:\n",
    "            # Re-stack x before passing it into f\n",
    "            x_stacked = tf.stack(x_unstacked, axis=0) # shape = (k,n)\n",
    "            g2.watch(x_stacked)\n",
    "            f_x = f(x_stacked) # shape = (k,)\n",
    "        \n",
    "        # Calculate gradient of f with respect to x\n",
    "        df_dx = g2.gradient(f_x, x_stacked) # shape = (k,n)\n",
    "        # Turn df/dx into a list of n tensors of shape (k,)\n",
    "        df_dx_unstacked = tf.unstack(df_dx, axis=0)\n",
    "\n",
    "    # Calculate 2nd derivatives\n",
    "    d2f_dx2 = []\n",
    "    for df_dxi,xi in zip(df_dx_unstacked, x_unstacked):\n",
    "        # Take 2nd derivative of each dimension separately:\n",
    "        #   d/dx_i (df/dx_i)\n",
    "        d2f_dx2.append(g1.gradient(df_dxi, xi))\n",
    "    \n",
    "    # Stack 2nd derivates\n",
    "    d2f_dx2_stacked = tf.stack(d2f_dx2, axis=1) # shape = (k,n)\n",
    "    \n",
    "    return d2f_dx2_stacked\n",
    "\n",
    "f = lambda q : tf.math.log(tf.math.reduce_sum(q**2, axis=1))\n",
    "x = tf.random.uniform((5,3))\n",
    "\n",
    "d2f_dx2 = calc_hessian_diag(f, x)\n",
    "print(d2f_dx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_fn(inputvar):\n",
    "    \n",
    "    params = [inputvar]\n",
    "    for p in mover_hmc.kernel_params[1:]:\n",
    "        params.append(p)\n",
    "    return -mover_hmc.log_posterior(*params)\n",
    "#fn_val, grads = tfp.math.value_and_gradient(target_fn, mover_hmc.kernel_params)\n",
    "\n",
    "calc_hessian_diag(target_fn,tf.expand_dims(mover_hmc.kernel_params[0],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train():\n",
    "    learning_rate = tf.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=1e-1,\n",
    "        decay_steps=10,\n",
    "        decay_rate=0.99,\n",
    "        staircase=True)\n",
    "\n",
    "\n",
    "    optimizer = tfp.optimizer.StochasticGradientLangevinDynamics(learning_rate=1e-1)\n",
    "    train_steps = 200\n",
    "    pbar = tqdm(range(train_steps))\n",
    "    loss_history = np.zeros((train_steps))\n",
    "    for i in pbar:\n",
    "        with tf.GradientTape() as t:\n",
    "            loss = -mover_hmc.log_posterior(*mover_hmc.kernel_params)\n",
    "        #loss_history[i] = loss.numpy()\n",
    "        #pbar.set_description(\"Loss %f\" % loss_history[i])\n",
    "\n",
    "        gradients = t.gradient(loss, mover_hmc.kernel_params)\n",
    "        optimizer.apply_gradients(zip(gradients, mover_hmc.kernel_params))\n",
    "#n=3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_history[8000:])\n",
    "plt.show()\n",
    "loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = mover_hmc.get_lengthscale()\n",
    "plt.plot(Z,lengths*np.ones_like(Z),'o',c='b')\n",
    "Zin = np.linspace(0,24,num=500,endpoint=False).astype(np.float64)[:,None]\n",
    "\n",
    "lengths = mover_hmc.get_lengthscale(X=Zin)\n",
    "plt.plot(Zin,lengths*np.ones_like(Zin))\n",
    "plt.show()\n",
    "\n",
    "amps = mover_hmc.get_amplitude()\n",
    "plt.plot(Z,amps,'o',c='b')\n",
    "Zin = np.linspace(0,24,num=500,endpoint=False).astype(np.float64)[:,None]\n",
    "amps = mover_hmc.get_amplitude(X=Zin)\n",
    "plt.plot(Zin,amps)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(s2,'-o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sample from the posterior\n",
    "kr = mover.hmc_sample(num_samples=1, skip=0, burn_in=0, num_leapfrog_steps=1, init_step=1e-8)\n",
    "# lengths = mover.get_lengthscale_samples()\n",
    "# amps = mover.get_amplitude_samples()\n",
    "# #  plot the sample for checking\n",
    "# plt.figure(figsize=(10,6))\n",
    "# Z_time=np.array([np.datetime64('2019') + np.timedelta64(int(k*60*60), 's') for k in Z])\n",
    "\n",
    "# for i in range(0,lengths.shape[0]):\n",
    "#     plt.plot(Z_time[np.argsort(Z_time)],lengths[i,np.argsort(Z_time)],c='C1',alpha=0.902,linewidth=1.0)\n",
    "\n",
    "# ax = plt.gca()\n",
    "# ax.xaxis_date()\n",
    "# ax.xaxis.set_major_formatter(myFmt)\n",
    "# plt.figure(figsize=(10,6))\n",
    "\n",
    "# for i in range(0,amps.shape[0]):\n",
    "#     plt.plot(Z_time[np.argsort(Z_time)],amps[i,np.argsort(Z_time)],c='C1', alpha=0.902,linewidth=1.0)\n",
    "# ax = plt.gca()\n",
    "# ax.xaxis_date()\n",
    "# ax.xaxis.set_major_formatter(myFmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ss = np.float64(1e-2)\n",
    "steps = []\n",
    "for j, param in enumerate(mover.kernel_params):\n",
    "    steps.append(ss)\n",
    "\n",
    "# steps = []\n",
    "# for j, param in enumerate(mover.kernel_params):\n",
    "#     if j==2:\n",
    "#         steps.append(ss)\n",
    "#     elif j==6:\n",
    "#         steps.append(ss)\n",
    "#     else:\n",
    "#         steps.append(0)\n",
    "start = time.time()\n",
    "\n",
    "num_samples=200#500\n",
    "burn=10\n",
    "start = time.time()\n",
    "mover.num_samples = num_samples\n",
    "#kr = mover.nuts_sample(num_samples=num_samples, skip=0, burn_in=burn, init_step=steps)\n",
    "\n",
    "end = time.time()\n",
    "print(i,end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mover_hmc.kernel_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples=10#500\n",
    "burn=10\n",
    "\n",
    "ss = np.float64(1e-3)\n",
    "\n",
    "\n",
    "steps = ss\n",
    "# for j, param in enumerate(mover_hmc.kernel_params):\n",
    "#     if j==2:\n",
    "#         steps.append(ss)\n",
    "#     else:\n",
    "#         steps.append(0)\n",
    "inner_kernel = tfp.mcmc.HamiltonianMonteCarlo(target_log_prob_fn=mover_hmc.log_posterior, step_size=steps, num_leapfrog_steps=20)\n",
    "kernel = tfp.mcmc.DualAveragingStepSizeAdaptation(inner_kernel, num_adaptation_steps=int(burn * 0.8))\n",
    "start = time.time()\n",
    "\n",
    "samples, kernel_results = tfp.mcmc.sample_chain(num_results=num_samples, num_burnin_steps=burn, num_steps_between_results=0, current_state=mover_hmc.kernel_params, kernel=inner_kernel)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "mover_hmc.samples_ = samples\n",
    "print(np.sum(kernel_results.is_accepted.numpy()/num_samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfp.mcmc.effective_sample_size(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfp.mcmc.effective_sample_size(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "359*10/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfp.mcmc.effective_sample_size(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(samples[1][:,:].numpy())\n",
    "plt.show()\n",
    "aa=tfp.mcmc.effective_sample_size(samples)[1].numpy()\n",
    "\n",
    "plt.plot(mover_hmc.kernel_params[1].numpy(),aa,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfp.mcmc.effective_sample_size(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def _fn(state_parts, seed):\n",
    "    next_state_parts = []\n",
    "    for j, param in enumerate(state_parts):\n",
    "        if j==1:\n",
    "            norm = tfd.Normal(loc=np.float64(0), scale=np.float64(0.005))\n",
    "\n",
    "            next_state_parts.append(state_parts[j] + norm.sample(sample_shape=state_parts[j].shape))\n",
    "        else:\n",
    "            next_state_parts.append(state_parts[j])\n",
    "\n",
    "    return next_state_parts\n",
    "\n",
    "\n",
    "num_samples=2000#00#500\n",
    "burn=200\n",
    "mover_hmc.num_samples = num_samples\n",
    "\n",
    "\n",
    "kernel = tfp.mcmc.MetropolisAdjustedLangevinAlgorithm(target_log_prob_fn=mover_hmc.log_posterior, step_size=0.000025)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "samples, kernel_results = tfp.mcmc.sample_chain(num_results=num_samples, num_burnin_steps=burn, num_steps_between_results=10, current_state=mover_hmc.kernel_params, kernel=kernel)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "mover_hmc.samples_ = samples\n",
    "print(np.sum(kernel_results.is_accepted.numpy()/num_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfp.mcmc.effective_sample_size(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(samples[1][:,:].numpy())\n",
    "plt.show()\n",
    "aa=tfp.mcmc.effective_sample_size(samples)[1].numpy()\n",
    "\n",
    "plt.plot(mover_hmc.kernel_params[1].numpy(),aa,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepsizes=np.std(samples[1].numpy(),axis=0)\n",
    "plt.plot(aa,stepsizes,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples=2000#500\n",
    "burn=2000\n",
    "\n",
    "ss = np.float64(1e-3)\n",
    "\n",
    "\n",
    "steps = []\n",
    "for j, param in enumerate(mover_hmc.kernel_params):\n",
    "    if j==1:\n",
    "        steps.append(ss*stepsizes)\n",
    "    else:\n",
    "        steps.append(ss*step_ls)\n",
    "inner_kernel = tfp.mcmc.HamiltonianMonteCarlo(target_log_prob_fn=mover_hmc.log_posterior, step_size=steps, num_leapfrog_steps=20)\n",
    "kernel = tfp.mcmc.DualAveragingStepSizeAdaptation(inner_kernel, num_adaptation_steps=int(burn * 0.8))\n",
    "start = time.time()\n",
    "\n",
    "samples, kernel_results = tfp.mcmc.sample_chain(num_results=num_samples, num_burnin_steps=burn, num_steps_between_results=0, current_state=mover_hmc.kernel_params, kernel=inner_kernel)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "mover_hmc.samples_ = samples\n",
    "print(np.sum(kernel_results.is_accepted.numpy()/num_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_ls=np.std(samples[0].numpy(),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfp.mcmc.effective_sample_size(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3574*10/60/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "\n",
    "tf.enable_v2_behavior()\n",
    "\n",
    "dtype = np.float32\n",
    "true_mean = dtype([0, 0, 0])\n",
    "true_cov = dtype([[1, 0.25, 0.25], [0.25, 1, 0.25], [0.25, 0.25, 1]])\n",
    "num_results = 500\n",
    "num_chains = 500\n",
    "\n",
    "# Target distribution is defined through the Cholesky decomposition\n",
    "chol = tf.linalg.cholesky(true_cov)\n",
    "target = tfd.MultivariateNormalTriL(loc=true_mean, scale_tril=chol)\n",
    "\n",
    "# Here we define the volatility function to be non-constant\n",
    "def volatility_fn(x):\n",
    "  # Stack the input tensors together\n",
    "  return 1. / (0.5 + 0.1 * tf.math.abs(x))\n",
    "\n",
    "# Initial state of the chain\n",
    "init_state = np.ones([num_chains, 3], dtype=dtype)\n",
    "\n",
    "# Run MALA with normal proposal for `num_results` iterations for\n",
    "# `num_chains` independent chains:\n",
    "states = tfp.mcmc.sample_chain(\n",
    "    num_results=num_results,\n",
    "    current_state=init_state,\n",
    "    kernel=tfp.mcmc.MetropolisAdjustedLangevinAlgorithm(\n",
    "        target_log_prob_fn=target.log_prob,\n",
    "        step_size=.1,\n",
    "        volatility_fn=volatility_fn),\n",
    "    num_burnin_steps=200,\n",
    "    num_steps_between_results=1,\n",
    "    trace_fn=None)\n",
    "\n",
    "sample_mean = tf.reduce_mean(states, axis=[0, 1])\n",
    "x = (states - sample_mean)[..., tf.newaxis]\n",
    "sample_cov = tf.reduce_mean(\n",
    "    tf.matmul(x, tf.transpose(x, [0, 1, 3, 2])), [0, 1])\n",
    "\n",
    "print('sample mean', sample_mean.numpy())\n",
    "print('sample covariance matrix', sample_cov.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 108.34\n",
    "2 295\n",
    "3 638\n",
    "4 1322"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_results.new_step_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps = []\n",
    "# for j, param in enumerate(mover.kernel_params):\n",
    "#     print(j,mover.kernel_params[j].shape)\n",
    "#     if j==2:\n",
    "#         steps.append(10*s1)\n",
    "#     elif j==6:\n",
    "#         steps.append(10*s2)\n",
    "#     else:\n",
    "#         steps.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "# 200/200 took 6.31 - run for 1000/1000 = 31.551hrs\n",
    "num_samples=250#00\n",
    "burn_in=100#500  ## 100/250\n",
    "num_runs=1#4\n",
    "rescale = 24\n",
    "\n",
    "for i in range(num_runs):\n",
    "    ss = np.float64(1e-3)\n",
    "    steps = []\n",
    "    for j, param in enumerate(mover.kernel_params):\n",
    "        steps.append(ss)\n",
    "    steps=opt_step\n",
    "    kr = mover.nuts_sample(num_samples=num_samples, skip=0, burn_in=burn_in, max_tree_depth=5, init_step=steps)\n",
    "   \n",
    "    # save the results\n",
    "    final_hmc_np = [j.numpy() for j in  mover.samples_]\n",
    "    with open('data/hmc_samples_p_' + str(i) + '.npy', 'wb') as fp:\n",
    "        pickle.dump(final_hmc_np, fp)\n",
    "        \n",
    "    lengths = mover.get_lengthscale_samples()\n",
    "    amps = mover.get_amplitude_samples()\n",
    "    np.save('data/len_sheep_p_' + str(i) + '.npy',lengths)\n",
    "    np.save('data/amp_sheep_p_' + str(i) + '.npy',amps)\n",
    "    \n",
    "\n",
    "    Zin = np.linspace(0,24,num=200,endpoint=False).astype(np.float64)[:,None]\n",
    "\n",
    "    # sample from the posterior)\n",
    "    lengths = mover.get_lengthscale_samples(X=Zin)\n",
    "    amps = mover.get_amplitude_samples(X=Zin)\n",
    "\n",
    "    np.save('data/full_len_sheep_p_' + str(i) + '.npy',lengths)\n",
    "    np.save('data/full_amp_sheep_p_' + str(i) + '.npy',amps)\n",
    "    np.save('data/Z_pred_p_' + str(i) + '.npy',Zin)\n",
    "\n",
    "    \n",
    "    end = time.time()\n",
    "    print(i,end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kr.new_step_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start = time.time()\n",
    "# 200/200 took 6.31 - run for 1000/1000 = 31.551hrs\n",
    "num_samples=1500\n",
    "burn_in=500\n",
    "num_runs=1\n",
    "rescale = 24\n",
    "\n",
    "for i in range(num_runs):\n",
    "    steps = []\n",
    "    \n",
    "    ss = np.float64(1e-1)\n",
    "    \n",
    "    for j, param in enumerate(mover_hmc.kernel_params):\n",
    "        if j==1:\n",
    "            steps.append(s1)\n",
    "        elif j==3:\n",
    "            steps.append(s2)\n",
    "        else:\n",
    "            steps.append(0)\n",
    "    kr = mover_hmc.hmc_sample(num_samples=num_samples, skip=0, burn_in=burn_in, num_leapfrog_steps=5, init_step=steps)\n",
    "   \n",
    "    # save the results\n",
    "    final_hmc_np = [j.numpy() for j in  mover_hmc.samples_]\n",
    "    with open('data/hmc_samples_p_' + str(i) + '.npy', 'wb') as fp:\n",
    "        pickle.dump(final_hmc_np, fp)\n",
    "        \n",
    "    lengths = mover_hmc.get_lengthscale_samples()\n",
    "    amps = mover_hmc.get_amplitude_samples()\n",
    "    np.save('data/len_sheep_p_' + str(i) + '.npy',lengths)\n",
    "    np.save('data/amp_sheep_p_' + str(i) + '.npy',amps)\n",
    "    \n",
    "\n",
    "    Zin = np.linspace(0,24,num=200,endpoint=False).astype(np.float64)[:,None]\n",
    "\n",
    "    # sample from the posterior)\n",
    "    lengths = mover_hmc.get_lengthscale_samples(X=Zin)\n",
    "    amps = mover_hmc.get_amplitude_samples(X=Zin)\n",
    "\n",
    "    np.save('data/full_len_sheep_p_' + str(i) + '.npy',lengths)\n",
    "    np.save('data/full_amp_sheep_p_' + str(i) + '.npy',amps)\n",
    "    np.save('data/Z_pred_p_' + str(i) + '.npy',Zin)\n",
    "\n",
    "    \n",
    "    end = time.time()\n",
    "    print(i,end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('time: ',10*(end - start)/60/60)\n",
    "\n",
    "print(np.sum(kernel_results.inner_results.is_accepted.numpy()/num_samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kr.new_step_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "25.4872/5*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mp in mover.kernel_params:\n",
    "    print(mp)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescale = 24\n",
    "Zin = np.linspace(0,24,num=500,endpoint=False).astype(np.float64)[:,None]\n",
    "\n",
    "lengths = mover_hmc.get_lengthscale_samples(X=Zin)\n",
    "amps = mover_hmc.get_amplitude_samples(X=Zin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Zin = np.linspace(0,24,num=500,endpoint=False).astype(np.float64)[:,None]\n",
    "\n",
    "# sample from the posterior)\n",
    "lengths = mover.get_lengthscale_samples(X=Zin)\n",
    "amps = mover.get_amplitude_samples(X=Zin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  plot the sample for checking\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "\n",
    "# Z_time=np.array([np.datetime64('2019') + np.timedelta64(int(k*60*60), 's') for k in Zin])\n",
    "\n",
    "# for i in range(0,lengths.shape[0]):\n",
    "#     plt.plot(Z_time[np.argsort(Z_time)],lengths[i,np.argsort(Z_time)],c='C1',alpha=0.902,linewidth=1.0)\n",
    "\n",
    "# ax = plt.gca()\n",
    "# ax.xaxis_date()\n",
    "# ax.xaxis.set_major_formatter(myFmt)\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "for i in range(0,amps.shape[0]):\n",
    "    plt.plot(Z_time[np.argsort(Z_time)],amps[i,np.argsort(Z_time)],c='C1', alpha=0.02,linewidth=1.0)\n",
    "ax = plt.gca()\n",
    "ax.xaxis_date()\n",
    "ax.xaxis.set_major_formatter(myFmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
